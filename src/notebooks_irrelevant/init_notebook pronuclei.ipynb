{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "# from unet import AttUNet, UNet, UNetWithPretrainedEncoder\n",
    "# from dataloader import ImageDataset, TransformWrapper\n",
    "import os\n",
    "import random\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torchvision import transforms as T\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "from PIL.ImageFile import ImageFile\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def apply_clahe(pil_img):\n",
    "    # Convert PIL image to NumPy array\n",
    "    img = np.array(pil_img)\n",
    "\n",
    "    # If grayscale\n",
    "    if len(img.shape) == 2:\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        img_clahe = clahe.apply(img)\n",
    "    # If RGB\n",
    "    elif len(img.shape) == 3:\n",
    "        img_lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "        l, a, b = cv2.split(img_lab)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        l_clahe = clahe.apply(l)\n",
    "        img_lab_clahe = cv2.merge((l_clahe, a, b))\n",
    "        img_clahe = cv2.cvtColor(img_lab_clahe, cv2.COLOR_LAB2RGB)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported image format\")\n",
    "\n",
    "    # Convert back to PIL image\n",
    "    return Image.fromarray(img_clahe)\n",
    "\n",
    "\n",
    "class TransformWrapper:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.image_transforms = T.Compose([\n",
    "            T.RandomHorizontalFlip(p=0.5),\n",
    "            T.RandomVerticalFlip(p=0.5),\n",
    "            T.RandomRotation(degrees=[30, 60, 90, 120, 150]),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        self.mask_transforms = T.Compose([\n",
    "            T.RandomHorizontalFlip(p=0.5),\n",
    "            T.RandomVerticalFlip(p=0.5),\n",
    "            T.RandomRotation(degrees=45),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    def __call__(self, image, mask):\n",
    "        # Apply the same random seed to ensure consistent transformations\n",
    "        seed = torch.randint(0, 2**32, (1, )).item()\n",
    "        torch.manual_seed(seed)\n",
    "        image = self.image_transforms(image)\n",
    "\n",
    "        torch.manual_seed(seed)\n",
    "        mask = self.mask_transforms(mask)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "class ImageDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 images: list[ImageFile],\n",
    "                 masks: list[ImageFile],\n",
    "                 transform: bool = False,\n",
    "                 image_size: int = 224):\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "        self.image_size = image_size\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[torch.FloatTensor, torch.FloatTensor]:\n",
    "        image = self.images[index]\n",
    "        mask = self.masks[index]\n",
    "\n",
    "        # Resize both image and mask\n",
    "        image = image.resize((self.image_size, self.image_size), Image.Resampling.LANCZOS)\n",
    "        mask = mask.resize((self.image_size, self.image_size), Image.Resampling.LANCZOS)\n",
    "\n",
    "        # Binary threshold for mask\n",
    "        binary_threshold = 100\n",
    "        mask = mask.point(lambda p: 255 if p > binary_threshold else 0)\n",
    "\n",
    "        # Random CLAHE on image\n",
    "        if np.random.rand() > 0.5:\n",
    "            image = apply_clahe(image)\n",
    "\n",
    "        # Random Gaussian blur on image with random kernel size\n",
    "        if np.random.rand() > 0.5:\n",
    "            kernel = np.random.choice([3, 5, 7, 9, 15,21])\n",
    "            image = T.GaussianBlur(kernel)(image)\n",
    "\n",
    "        normalize_tensor = T.Compose([\n",
    "            T.Lambda(lambda x: x.convert(\"RGB\")),\n",
    "            T.ToTensor(),\n",
    "            # Uncomment if normalization is desired:\n",
    "            # T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "            #             std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "        if self.transform:\n",
    "            # Random horizontal and vertical flips\n",
    "            if np.random.rand() > 0.5:\n",
    "                image = F.hflip(image)\n",
    "                mask = F.hflip(mask)\n",
    "            if np.random.rand() > 0.5:\n",
    "                image = F.vflip(image)\n",
    "                mask = F.vflip(mask)\n",
    "            # Random rotation, shear, and resize (scale)\n",
    "            angle = random.uniform(-90, 90)\n",
    "            shear = random.uniform(-20, 20)\n",
    "            scale = random.uniform(0.5, 1.0)\n",
    "            image = F.affine(image, angle=angle, translate=(0, 0), scale=scale, shear=shear, interpolation=Image.BILINEAR)\n",
    "            mask = F.affine(mask, angle=angle, translate=(0, 0), scale=scale, shear=shear, interpolation=Image.NEAREST)\n",
    "\n",
    "        image = normalize_tensor(image)\n",
    "        mask = T.ToTensor()(mask)\n",
    "        return image, mask\n",
    "\n",
    "data_pth = Path(\n",
    "    '/Users/tsakalis/Downloads/ECImageAnalysisMouse/New Binary Masks')\n",
    "blastocyst_pth = Path('/home/tsakalis/ntua/phd/cellforge/cellforge/data')\n",
    "\n",
    "full_path = \"/Users/tsakalis/ntua/cellforge/data/D2016.07.08_S1366_I149_11\"\n",
    "\n",
    "blastocyst_images_pth = blastocyst_pth / 'annotation_pn/images_pn'\n",
    "blastocyst_msk_pth = blastocyst_pth / 'annotation_pn/masks_pn'\n",
    "\n",
    "smooth = 1e-15\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "\n",
    "def dice_coef(y_pred, y_true):\n",
    "\n",
    "    intersection = torch.sum(y_true.flatten() * y_pred.flatten())\n",
    "    return (2. * intersection + smooth) / (\n",
    "        torch.sum(y_true).flatten() + torch.sum(y_pred).flatten() + smooth)\n",
    "\n",
    "\n",
    "def dice_loss(y_pred, y_true):\n",
    "\n",
    "    return 1.0 - dice_coef(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_file_paths = sorted(list((data_pth / \"images\").glob('*.png')),\n",
    "#                           key=lambda x: x.stem)\n",
    "# mask_file_paths = sorted(list((data_pth / \"masks\").glob('*.png')),\n",
    "#                          key=lambda x: x.stem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy.ndimage import center_of_mass\n",
    "\n",
    "\n",
    "def crop_around_center(image: Image.Image, mask: Image.Image,\n",
    "                       crop_size: int) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Finds the center of mass of the non-zero pixels in the image\n",
    "    and crops the image around that point.\n",
    "\n",
    "    Args:\n",
    "        image (PIL.Image.Image): Input image (grayscale or binary recommended).\n",
    "        crop_size (int): Size of the square crop (e.g., 128 for 128x128 crop).\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image.Image: Cropped image around the center of mass.\n",
    "    \"\"\"\n",
    "    # Convert image to grayscale and NumPy array\n",
    "    image_array = np.array(image.convert(\"L\"))\n",
    "\n",
    "    # Find the center of mass of non-zero pixels\n",
    "    com = center_of_mass(image_array)\n",
    "\n",
    "    # Round to integers for pixel indexing\n",
    "    center_y, center_x = map(int, com)\n",
    "\n",
    "    # Calculate crop box\n",
    "    half_crop = crop_size // 2\n",
    "    left = max(center_x - half_crop, 0)\n",
    "    upper = max(center_y - half_crop, 0)\n",
    "    right = min(center_x + half_crop, image.width)\n",
    "    lower = min(center_y + half_crop, image.height)\n",
    "\n",
    "    # Crop the image\n",
    "    cropped_image = image.crop((left, upper, right, lower))\n",
    "\n",
    "    cropped_mask = mask.crop((left, upper, right, lower))\n",
    "    return cropped_image, cropped_mask\n",
    "\n",
    "\n",
    "# Example usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_paths = sorted(list(blastocyst_images_pth.glob('*.jpg')),\n",
    "                          key=lambda x: x.stem)\n",
    "mask_file_paths = sorted(list(blastocyst_msk_pth.glob('*.png')),\n",
    "                         key=lambda x: x.stem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/tsakalis/ntua/phd/cellforge/cellforge/data/annotation_pn/images_pn')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blastocyst_images_pth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m     13\u001b[0m random\u001b[38;5;241m.\u001b[39mshuffle(c)\n\u001b[0;32m---> 15\u001b[0m images, masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mc)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# def remove_alpha(img):\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#     if img.mode == 'RGBA':  # If image has an alpha channel\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#         background = Image.new('RGB', img.size,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#     cropped_images.append(cropped)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#     cropped_masks.append(cropped_mask)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m ImageDataset(images\u001b[38;5;241m=\u001b[39mimages[:\u001b[38;5;241m400\u001b[39m],\n\u001b[1;32m     39\u001b[0m                              masks\u001b[38;5;241m=\u001b[39mmasks[:\u001b[38;5;241m400\u001b[39m],\n\u001b[1;32m     40\u001b[0m                              transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "# image_file_paths = sorted(list((data_pth / \"images\").glob('*.jpg')),\n",
    "#                           key=lambda x: x.stem)\n",
    "# mask_file_paths = sorted(list((data_pth / \"masks\").glob('*.png')),\n",
    "#                          key=lambda x: x.stem)\n",
    "\n",
    "# print(\"... Loading images ...\")\n",
    "images = [Image.open(img_path) for img_path in tqdm(image_file_paths)]\n",
    "masks = [Image.open(msk_pth) for msk_pth in tqdm(mask_file_paths)]\n",
    "\n",
    "c = list(zip(images, masks))\n",
    "import random\n",
    "\n",
    "random.shuffle(c)\n",
    "\n",
    "images, masks = zip(*c)\n",
    "\n",
    "# def remove_alpha(img):\n",
    "#     if img.mode == 'RGBA':  # If image has an alpha channel\n",
    "#         background = Image.new('RGB', img.size,\n",
    "#                                (255, 255, 255))  # Create white background\n",
    "#         background.paste(img, mask=img.split()[3])  # Use alpha channel as mask\n",
    "#         return background\n",
    "#     return img  # Return unchanged if no alpha channel\n",
    "\n",
    "# # Process images and masks\n",
    "# images = [remove_alpha(img) for img in tqdm(images)]\n",
    "# masks = [remove_alpha(msk) for msk in tqdm(masks)]\n",
    "\n",
    "# cropped_images = []\n",
    "# cropped_masks = []\n",
    "# for image, mask in zip(images, masks):\n",
    "\n",
    "#     cropped, cropped_mask = crop_around_center(image, mask, crop_size=200 * 3)\n",
    "\n",
    "#     cropped_images.append(cropped)\n",
    "#     cropped_masks.append(cropped_mask)\n",
    "\n",
    "train_dataset = ImageDataset(images=images[:400],\n",
    "                             masks=masks[:400],\n",
    "                             transform=True)\n",
    "val_dataset = ImageDataset(images=images[400:800], masks=masks[400:800])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2756805846.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    len(train_dataloader)/\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "len(train_dataloader)/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torchvision import transforms as T\n",
    "import torchvision.transforms.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m im, gt \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_dataloader\u001b[49m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "for im, gt in train_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsakalis/ntua/phd/cellforge/cellforge_venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "model = smp.Unet(\n",
    "        encoder_name=\"resnet152\",\n",
    "        encoder_weights=\"imagenet\",\n",
    "        in_channels=3,\n",
    "        classes=2,\n",
    "    )\n",
    "model.to(device)\n",
    "lr = 5e-5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def validate(model, val_dataloader):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img_batch, gt_msk_batch in val_dataloader:\n",
    "\n",
    "            img_batch = img_batch.to(device)\n",
    "            gt_msk_batch = gt_msk_batch.to(device)\n",
    "\n",
    "            pred_mask = model(img_batch)\n",
    "\n",
    "            loss = dice_loss(torch.sigmoid(pred_mask), gt_msk_batch)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    mean_val_loss = val_loss / len(val_dataloader)\n",
    "    return mean_val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2054540/3522360610.py:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[0;32m----> 2\u001b[0m     progress_bar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[43mtrain_dataloader\u001b[49m, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_dataloader))\n\u001b[1;32m      4\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m img_batch, gt_msk_batch \u001b[38;5;129;01min\u001b[39;00m progress_bar:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    progress_bar = tqdm(train_dataloader, total=len(train_dataloader))\n",
    "\n",
    "    train_loss = 0\n",
    "    for img_batch, gt_msk_batch in progress_bar:\n",
    "        img_batch = img_batch.to(device)\n",
    "        gt_msk_batch = gt_msk_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            pred_mask = model(img_batch)\n",
    "\n",
    "            loss = dice_loss(torch.sigmoid(pred_mask), gt_msk_batch)\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        progress_bar.set_description(str(loss.item()))\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    val_loss = validate(model, val_dataloader)\n",
    "\n",
    "    print(\n",
    "        f'Epoch {epoch+1} | TrainLoss: {train_loss/len(train_dataloader)} ValLoss: {val_loss}'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mimg_batch\u001b[49m[\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m0\u001b[39m,:]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img_batch' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img_batch[10,0,:].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 40\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m iou, dice\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# # Example usage\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# pred_mask = torch.randint(0, 2, (256, 256),\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#                           dtype=torch.float32)  # Example predicted mask\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# gt_mask = torch.randint(0, 2, (256, 256),\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#                         dtype=torch.float32)  # Example ground truth mask\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m iou_fn, dice_fn \u001b[38;5;241m=\u001b[39m compute_iou_and_dice(torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[43mpred_mask\u001b[49m),\n\u001b[1;32m     41\u001b[0m                                        gt_msk_batch\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIoU: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miou_fn\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Dice: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdice_fn\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_mask' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def compute_iou_and_dice(pred: torch.Tensor,\n",
    "                         gt: torch.Tensor) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Compute IoU and Dice metrics for binary segmentation masks using PyTorch.\n",
    "\n",
    "    Args:\n",
    "        pred (torch.Tensor): Predicted binary mask (0 or 1), shape (H, W).\n",
    "        gt (torch.Tensor): Ground truth binary mask (0 or 1), shape (H, W).\n",
    "\n",
    "    Returns:\n",
    "        tuple[float, float]: IoU and Dice scores.\n",
    "    \"\"\"\n",
    "    # Ensure binary masks (threshold at 0.5 for soft predictions)\n",
    "    pred = (pred > 0.5).float()\n",
    "    gt = (gt > 0.5).float()\n",
    "\n",
    "    # Compute intersection and union\n",
    "    intersection = torch.sum(pred * gt)\n",
    "    union = torch.sum(pred) + torch.sum(gt) - intersection\n",
    "\n",
    "    # Compute IoU\n",
    "    iou = (intersection / union).item() if union > 0 else 0.0\n",
    "\n",
    "    # Compute Dice coefficient\n",
    "    dice = (2 * intersection / (torch.sum(pred) + torch.sum(gt))).item() if (\n",
    "        torch.sum(pred) + torch.sum(gt)) > 0 else 0.0\n",
    "\n",
    "    return iou, dice\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# pred_mask = torch.randint(0, 2, (256, 256),\n",
    "#                           dtype=torch.float32)  # Example predicted mask\n",
    "# gt_mask = torch.randint(0, 2, (256, 256),\n",
    "#                         dtype=torch.float32)  # Example ground truth mask\n",
    "\n",
    "iou_fn, dice_fn = compute_iou_and_dice(torch.sigmoid(pred_mask),\n",
    "                                       gt_msk_batch.to(device))\n",
    "print(f\"IoU: {iou_fn:.4f}, Dice: {dice_fn:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"/home/tsakalis/ntua/phd/cellforge/cellforge/model_weights/big_good_pn_model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(\n",
    "        encoder_name=\"resnext101_32x48d\",#\"resnext101_32x48d\",\n",
    "        encoder_weights=\"instagram\",\n",
    "        in_channels=3,\n",
    "        classes=3,\n",
    "    )\n",
    "\n",
    "model_pronuclei = smp.Unet(\n",
    "        encoder_name=\"resnext101_32x48d\",\n",
    "        encoder_weights=\"instagram\",\n",
    "        in_channels=3,\n",
    "        classes=4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 12288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(12288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(12288, 12288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(12288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(12288, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 12288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(12288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(12288, 12288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(12288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(12288, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 12288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(12288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(12288, 12288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(12288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(12288, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(3072, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(768, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pronuclei.load_state_dict(torch.load(\"/home/tsakalis/ntua/phd/cellforge/cellforge/model_weights/pronuclei_komple_with_embryo_HUGE.pt\", weights_only=True))\n",
    "model_pronuclei.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "ResNetEncoder: 1-1                     [-1, 3, 224, 224]         --\n",
      "|    Conv2d: 2-1                       [-1, 64, 112, 112]        9,408\n",
      "|    BatchNorm2d: 2-2                  [-1, 64, 112, 112]        128\n",
      "|    ReLU: 2-3                         [-1, 64, 112, 112]        --\n",
      "|    MaxPool2d: 2-4                    [-1, 64, 56, 56]          --\n",
      "|    Sequential: 2-5                   [-1, 256, 56, 56]         --\n",
      "|    |    Bottleneck: 3-1              [-1, 256, 56, 56]         1,178,624\n",
      "|    |    Bottleneck: 3-2              [-1, 256, 56, 56]         1,456,640\n",
      "|    |    Bottleneck: 3-3              [-1, 256, 56, 56]         1,456,640\n",
      "|    Sequential: 2-6                   [-1, 512, 28, 28]         --\n",
      "|    |    Bottleneck: 3-4              [-1, 512, 28, 28]         5,158,912\n",
      "|    |    Bottleneck: 3-5              [-1, 512, 28, 28]         5,813,248\n",
      "|    |    Bottleneck: 3-6              [-1, 512, 28, 28]         5,813,248\n",
      "|    |    Bottleneck: 3-7              [-1, 512, 28, 28]         5,813,248\n",
      "|    Sequential: 2-7                   [-1, 1024, 14, 14]        --\n",
      "|    |    Bottleneck: 3-8              [-1, 1024, 14, 14]        20,606,976\n",
      "|    |    Bottleneck: 3-9              [-1, 1024, 14, 14]        23,226,368\n",
      "|    |    Bottleneck: 3-10             [-1, 1024, 14, 14]        23,226,368\n",
      "|    |    Bottleneck: 3-11             [-1, 1024, 14, 14]        23,226,368\n",
      "|    |    Bottleneck: 3-12             [-1, 1024, 14, 14]        23,226,368\n",
      "|    |    Bottleneck: 3-13             [-1, 1024, 14, 14]        23,226,368\n",
      "|    |    Bottleneck: 3-14             [-1, 1024, 14, 14]        23,226,368\n",
      "|    |    Bottleneck: 3-15             [-1, 1024, 14, 14]        23,226,368\n",
      "|    |    Bottleneck: 3-16             [-1, 1024, 14, 14]        23,226,368\n",
      "|    |    Bottleneck: 3-17             [-1, 1024, 14, 14]        23,226,368\n",
      "|    |    Bottleneck: 3-18             [-1, 1024, 14, 14]        23,226,368\n",
      "|    |    Bottleneck: 3-19             [-1, 1024, 14, 14]        23,226,368\n",
      "|    |    Bottleneck: 3-20             [-1, 1024, 14, 14]        23,226,368\n",
      "|    |    Bottleneck: 3-21             [-1, 1024, 14, 14]        23,226,368\n",
      "|    |    Bottleneck: 3-22             [-1, 1024, 14, 14]        23,226,368\n",
      "|    |    Bottleneck: 3-23             [-1, 1024, 14, 14]        23,226,368\n",
      "|    |    Bottleneck: 3-24             [-1, 1024, 14, 14]        23,226,368\n",
      "|    |    Bottleneck: 3-25             [-1, 1024, 14, 14]        23,226,368\n",
      "|    |    Bottleneck: 3-26             [-1, 1024, 14, 14]        23,226,368\n",
      "|    |    Bottleneck: 3-27             [-1, 1024, 14, 14]        23,226,368\n",
      "|    |    Bottleneck: 3-28             [-1, 1024, 14, 14]        23,226,368\n",
      "|    |    Bottleneck: 3-29             [-1, 1024, 14, 14]        23,226,368\n",
      "|    |    Bottleneck: 3-30             [-1, 1024, 14, 14]        23,226,368\n",
      "|    Sequential: 2-8                   [-1, 2048, 7, 7]          --\n",
      "|    |    Bottleneck: 3-31             [-1, 2048, 7, 7]          82,370,560\n",
      "|    |    Bottleneck: 3-32             [-1, 2048, 7, 7]          92,852,224\n",
      "|    |    Bottleneck: 3-33             [-1, 2048, 7, 7]          92,852,224\n",
      "UnetDecoder: 1-2                       [-1, 16, 224, 224]        --\n",
      "|    Identity: 2-9                     [-1, 2048, 7, 7]          --\n",
      "|    ModuleList: 2                     []                        --\n",
      "|    |    DecoderBlock: 3-34           [-1, 256, 14, 14]         7,668,736\n",
      "|    |    DecoderBlock: 3-35           [-1, 128, 28, 28]         1,032,704\n",
      "|    |    DecoderBlock: 3-36           [-1, 64, 56, 56]          258,304\n",
      "|    |    DecoderBlock: 3-37           [-1, 32, 112, 112]        46,208\n",
      "|    |    DecoderBlock: 3-38           [-1, 16, 224, 224]        6,976\n",
      "SegmentationHead: 1-3                  [-1, 3, 224, 224]         --\n",
      "|    Conv2d: 2-10                      [-1, 3, 224, 224]         435\n",
      "|    Identity: 2-11                    [-1, 3, 224, 224]         --\n",
      "|    Activation: 2-12                  [-1, 3, 224, 224]         --\n",
      "|    |    Identity: 3-39               [-1, 3, 224, 224]         --\n",
      "==========================================================================================\n",
      "Total params: 835,375,539\n",
      "Trainable params: 835,375,539\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 155.48\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 1977.99\n",
      "Params size (MB): 3186.70\n",
      "Estimated Total Size (MB): 5165.27\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNetEncoder: 1-1                     [-1, 3, 224, 224]         --\n",
       "|    Conv2d: 2-1                       [-1, 64, 112, 112]        9,408\n",
       "|    BatchNorm2d: 2-2                  [-1, 64, 112, 112]        128\n",
       "|    ReLU: 2-3                         [-1, 64, 112, 112]        --\n",
       "|    MaxPool2d: 2-4                    [-1, 64, 56, 56]          --\n",
       "|    Sequential: 2-5                   [-1, 256, 56, 56]         --\n",
       "|    |    Bottleneck: 3-1              [-1, 256, 56, 56]         1,178,624\n",
       "|    |    Bottleneck: 3-2              [-1, 256, 56, 56]         1,456,640\n",
       "|    |    Bottleneck: 3-3              [-1, 256, 56, 56]         1,456,640\n",
       "|    Sequential: 2-6                   [-1, 512, 28, 28]         --\n",
       "|    |    Bottleneck: 3-4              [-1, 512, 28, 28]         5,158,912\n",
       "|    |    Bottleneck: 3-5              [-1, 512, 28, 28]         5,813,248\n",
       "|    |    Bottleneck: 3-6              [-1, 512, 28, 28]         5,813,248\n",
       "|    |    Bottleneck: 3-7              [-1, 512, 28, 28]         5,813,248\n",
       "|    Sequential: 2-7                   [-1, 1024, 14, 14]        --\n",
       "|    |    Bottleneck: 3-8              [-1, 1024, 14, 14]        20,606,976\n",
       "|    |    Bottleneck: 3-9              [-1, 1024, 14, 14]        23,226,368\n",
       "|    |    Bottleneck: 3-10             [-1, 1024, 14, 14]        23,226,368\n",
       "|    |    Bottleneck: 3-11             [-1, 1024, 14, 14]        23,226,368\n",
       "|    |    Bottleneck: 3-12             [-1, 1024, 14, 14]        23,226,368\n",
       "|    |    Bottleneck: 3-13             [-1, 1024, 14, 14]        23,226,368\n",
       "|    |    Bottleneck: 3-14             [-1, 1024, 14, 14]        23,226,368\n",
       "|    |    Bottleneck: 3-15             [-1, 1024, 14, 14]        23,226,368\n",
       "|    |    Bottleneck: 3-16             [-1, 1024, 14, 14]        23,226,368\n",
       "|    |    Bottleneck: 3-17             [-1, 1024, 14, 14]        23,226,368\n",
       "|    |    Bottleneck: 3-18             [-1, 1024, 14, 14]        23,226,368\n",
       "|    |    Bottleneck: 3-19             [-1, 1024, 14, 14]        23,226,368\n",
       "|    |    Bottleneck: 3-20             [-1, 1024, 14, 14]        23,226,368\n",
       "|    |    Bottleneck: 3-21             [-1, 1024, 14, 14]        23,226,368\n",
       "|    |    Bottleneck: 3-22             [-1, 1024, 14, 14]        23,226,368\n",
       "|    |    Bottleneck: 3-23             [-1, 1024, 14, 14]        23,226,368\n",
       "|    |    Bottleneck: 3-24             [-1, 1024, 14, 14]        23,226,368\n",
       "|    |    Bottleneck: 3-25             [-1, 1024, 14, 14]        23,226,368\n",
       "|    |    Bottleneck: 3-26             [-1, 1024, 14, 14]        23,226,368\n",
       "|    |    Bottleneck: 3-27             [-1, 1024, 14, 14]        23,226,368\n",
       "|    |    Bottleneck: 3-28             [-1, 1024, 14, 14]        23,226,368\n",
       "|    |    Bottleneck: 3-29             [-1, 1024, 14, 14]        23,226,368\n",
       "|    |    Bottleneck: 3-30             [-1, 1024, 14, 14]        23,226,368\n",
       "|    Sequential: 2-8                   [-1, 2048, 7, 7]          --\n",
       "|    |    Bottleneck: 3-31             [-1, 2048, 7, 7]          82,370,560\n",
       "|    |    Bottleneck: 3-32             [-1, 2048, 7, 7]          92,852,224\n",
       "|    |    Bottleneck: 3-33             [-1, 2048, 7, 7]          92,852,224\n",
       "UnetDecoder: 1-2                       [-1, 16, 224, 224]        --\n",
       "|    Identity: 2-9                     [-1, 2048, 7, 7]          --\n",
       "|    ModuleList: 2                     []                        --\n",
       "|    |    DecoderBlock: 3-34           [-1, 256, 14, 14]         7,668,736\n",
       "|    |    DecoderBlock: 3-35           [-1, 128, 28, 28]         1,032,704\n",
       "|    |    DecoderBlock: 3-36           [-1, 64, 56, 56]          258,304\n",
       "|    |    DecoderBlock: 3-37           [-1, 32, 112, 112]        46,208\n",
       "|    |    DecoderBlock: 3-38           [-1, 16, 224, 224]        6,976\n",
       "SegmentationHead: 1-3                  [-1, 3, 224, 224]         --\n",
       "|    Conv2d: 2-10                      [-1, 3, 224, 224]         435\n",
       "|    Identity: 2-11                    [-1, 3, 224, 224]         --\n",
       "|    Activation: 2-12                  [-1, 3, 224, 224]         --\n",
       "|    |    Identity: 3-39               [-1, 3, 224, 224]         --\n",
       "==========================================================================================\n",
       "Total params: 835,375,539\n",
       "Trainable params: 835,375,539\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 155.48\n",
       "==========================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 1977.99\n",
       "Params size (MB): 3186.70\n",
       "Estimated Total Size (MB): 5165.27\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m pred_masks_all \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m all_images \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img_batch, gt_msk_batch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mval_dataloader\u001b[49m:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast():\n\u001b[1;32m     11\u001b[0m         pred_mask \u001b[38;5;241m=\u001b[39m model(img_batch\u001b[38;5;241m.\u001b[39mto(device))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "gt_masks_all = []\n",
    "pred_masks_all = []\n",
    "\n",
    "all_images = []\n",
    "\n",
    "\n",
    "for img_batch, gt_msk_batch in val_dataloader:\n",
    "\n",
    "    with autocast():\n",
    "        pred_mask = model(img_batch.to(device))\n",
    "    all_images.append(img_batch)\n",
    "    pred_masks_all.append(pred_mask.to('cpu'))\n",
    "    gt_masks_all.append(gt_msk_batch.to('cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import JaccardIndex, Dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_masks_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m iou_fn \u001b[38;5;241m=\u001b[39m JaccardIndex(task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.90\u001b[39m)\n\u001b[1;32m      2\u001b[0m dice_fn \u001b[38;5;241m=\u001b[39m Dice(threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.90\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m iou_fn(torch\u001b[38;5;241m.\u001b[39msigmoid(torch\u001b[38;5;241m.\u001b[39mvstack(\u001b[43mpred_masks_all\u001b[49m)), torch\u001b[38;5;241m.\u001b[39mvstack(gt_masks_all))\n\u001b[1;32m      6\u001b[0m dice_fn(\n\u001b[1;32m      7\u001b[0m     torch\u001b[38;5;241m.\u001b[39msigmoid(torch\u001b[38;5;241m.\u001b[39mvstack(pred_masks_all)),\n\u001b[1;32m      8\u001b[0m     torch\u001b[38;5;241m.\u001b[39mvstack(gt_masks_all)\u001b[38;5;241m.\u001b[39mlong(),\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIoU: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miou_fn(torch\u001b[38;5;241m.\u001b[39msigmoid(torch\u001b[38;5;241m.\u001b[39mvstack(pred_masks_all)),\u001b[38;5;250m \u001b[39mtorch\u001b[38;5;241m.\u001b[39mvstack(gt_masks_all))\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_masks_all' is not defined"
     ]
    }
   ],
   "source": [
    "iou_fn = JaccardIndex(task='binary', threshold=0.90)\n",
    "dice_fn = Dice(threshold=0.90)\n",
    "\n",
    "iou_fn(torch.sigmoid(torch.vstack(pred_masks_all)), torch.vstack(gt_masks_all))\n",
    "\n",
    "dice_fn(\n",
    "    torch.sigmoid(torch.vstack(pred_masks_all)),\n",
    "    torch.vstack(gt_masks_all).long(),\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"IoU: {iou_fn(torch.sigmoid(torch.vstack(pred_masks_all)), torch.vstack(gt_masks_all)):.3f}\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Dice Coeff: {dice_fn(torch.sigmoid(torch.vstack(pred_masks_all)), torch.vstack(gt_masks_all).long()):.3f}\"\n",
    ")\n",
    "\n",
    "sample_pred_mask = torch.sigmoid(pred_masks_all[0][3][0].detach())\n",
    "\n",
    "sample_gt_mask = gt_masks_all[0][3][0].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage.morphology import binary_dilation\n",
    "slide_id = 'D2016.10.18_S1418_I149_6'\n",
    "sample_path = Path(\n",
    "    \"/home/tsakalis/ntua/phd/cellforge/cellforge/data/\")\n",
    "def inference_whole_slide(model,slide_pth: Path, max_frame: int):\n",
    "    \n",
    "\n",
    "    image_file_paths = sorted(list(slide_pth.glob('*.jpg')),\n",
    "                            key=lambda x: int(x.stem))[:max_frame]\n",
    "\n",
    "    images = [Image.open(img_path) for img_path in tqdm(image_file_paths)]\n",
    "\n",
    "    val_dataset = ImageCircleDataset(images=images)\n",
    "\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    from torch.cuda.amp import autocast\n",
    "\n",
    "    all_masks = []\n",
    "    for inpt_images, _ in val_dataloader:\n",
    "        with torch.no_grad():\n",
    "            with autocast():\n",
    "                pred_mask = model(inpt_images.to(device))\n",
    "                masks = torch.sigmoid(pred_mask).cpu().numpy()>0.9\n",
    "                all_masks.extend([msk for msk in masks])\n",
    "    \n",
    "\n",
    "    pn_size = []\n",
    "    final_images = []\n",
    "    upscaled_masks = []\n",
    "    isolated_pns = []\n",
    "    for pil_img, mask in zip(images[:], all_masks[:]):\n",
    "        # Ensure the mask is 2D by removing extra dimensions\n",
    "        # pil_img = pil_img.resize((224, 224), Image.Resampling.LANCZOS)\n",
    "        image_ar = np.stack(3*[np.array(pil_img)])\n",
    "        \n",
    "        upscaled_mask1 = cv2.resize(mask[0].astype(np.uint8), (500,500), interpolation=cv2.INTER_NEAREST)\n",
    "        upscaled_mask2 = cv2.resize(mask[1].astype(np.uint8), (500,500), interpolation=cv2.INTER_NEAREST)\n",
    "        upscaled_mask3 = cv2.resize(mask[-1].astype(np.uint8), (500,500), interpolation=cv2.INTER_NEAREST)\n",
    "        # pn_size.append(upscaled_mask.sum())\n",
    "    \n",
    "\n",
    "        upscaled_masks.append((upscaled_mask1, upscaled_mask2))\n",
    "        image_pn_isolated = image_ar.copy()\n",
    "        image_pn_isolated[:,~upscaled_mask1.astype(bool)] = 0\n",
    "        isolated_pns.append(image_pn_isolated.transpose(1,2,0))\n",
    "        # image_ar[0,upscaled_mask1.astype(bool)] = 240\n",
    "        # image_ar[1,upscaled_mask2.astype(bool)] = 240\n",
    "        image_ar[2,~upscaled_mask3.astype(bool)] = 240\n",
    "\n",
    "\n",
    "        final_images.append(Image.fromarray(image_ar.transpose(1,2,0)))\n",
    "\n",
    "    return final_images, upscaled_masks, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def video_writer_context(output_path, frame_height, frame_width, fps=5):\n",
    "    # Create a dummy figure to get graph size\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot([0, 1], [0, 1])\n",
    "    fig.canvas.draw()\n",
    "    graph_h, graph_w = fig.canvas.get_width_height()\n",
    "    plt.close(fig)\n",
    "\n",
    "    scale = frame_height / graph_h\n",
    "    graph_resized_width = int(graph_w * scale)\n",
    "    output_size = (frame_width + graph_resized_width, frame_height)\n",
    "\n",
    "    output = cv2.VideoWriter(\n",
    "        str(output_path),\n",
    "        cv2.VideoWriter_fourcc(*'XVID'),\n",
    "        fps,\n",
    "        output_size\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        yield output, graph_resized_width\n",
    "    finally:\n",
    "        output.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "def generate_video(slide_images, slide_masks, output_path, frame_height=500, frame_width=500):\n",
    "    pn_size1 = []\n",
    "    pn_size2 = []\n",
    "\n",
    "    with video_writer_context(output_path, frame_height, frame_width) as (output, graph_resized_width):\n",
    "        for frame_idx, frame in enumerate(slide_images):\n",
    "\n",
    "            if len(slide_masks[frame_idx])==2:\n",
    "\n",
    "                pn_size1.append(slide_masks[frame_idx][0].sum())\n",
    "                pn_size2.append(slide_masks[frame_idx][1].sum())\n",
    "\n",
    "            x = np.arange(start=0, stop=frame_idx + 1, step=1)\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(x, pn_size1)\n",
    "            ax.plot(x, pn_size2)\n",
    "            ax.set_title(f\"Accumulated PN Size (Frame {frame_idx})\")\n",
    "            ax.set_xlabel('Frame')\n",
    "            ax.set_ylabel('Accumulated Area')\n",
    "            fig.tight_layout()\n",
    "            fig.canvas.draw()\n",
    "\n",
    "            plot_img = np.asarray(fig.canvas.buffer_rgba())[:, :, :3]\n",
    "            plt.close(fig)\n",
    "\n",
    "            plot_resized = cv2.resize(plot_img, (graph_resized_width, frame_height))\n",
    "            plot_bgr = cv2.cvtColor(plot_resized, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            combined = np.hstack((np.array(frame), plot_bgr))\n",
    "\n",
    "            output.write(combined)\n",
    "            cv2.imshow(\"output\", combined)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_video(slide_images, slide_masks, sample_idx):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "from pathlib import Path\n",
    "from random import shuffle\n",
    "from typing import Callable, Literal\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader, Dataset, dataloader\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from segmentation_utils.dataloader import ImageDataset, ImageCircleDataset\n",
    "from PIL import Image\n",
    "\n",
    "from enum import StrEnum\n",
    "\n",
    "def create_all_masks_separate(whole_embryo_segmentation_model: nn.Module):\n",
    "    \"\"\"\n",
    "    This function will take the pronuclei masks and create the other 2 classes.\n",
    "\n",
    "    We will need some extra samples to be used as counter examples\n",
    "    (when pronuclei are not showing).\n",
    "\n",
    "    \"\"\"\n",
    "    DEVICE = \"cuda\"\n",
    "    BATCH_SIZE = 32\n",
    "    MASK_THRESHOLD = 0.9\n",
    "    IMAGE_SIZE = 224\n",
    "\n",
    "    base_cicle_pth = Path(\"/media/tsakalis/STORAGE/phd/pronuclei_tracking\")\n",
    "    timelapse_pth = Path(\n",
    "        \"/home/tsakalis/ntua/phd/cellforge/cellforge/data/raw_timelapses\"\n",
    "    )\n",
    "\n",
    "    all_circle_data = list((base_cicle_pth / \"fitted_circles_samples\").glob(\"*.json\"))\n",
    "    import json\n",
    "\n",
    "    images = []\n",
    "    masks = []\n",
    "    for circle_file_pth in tqdm(all_circle_data):\n",
    "        slide_id = str(circle_file_pth).split(\"/\")[-1][:-5]\n",
    "        with open(circle_file_pth) as f:\n",
    "            circles = json.load(f)\n",
    "\n",
    "        for circle in circles:\n",
    "            full_frame_pth = timelapse_pth / f\"{slide_id}/{circle['frame']}_0.jpg\"\n",
    "            frame_img = Image.open(full_frame_pth)\n",
    "            mask = np.zeros((500, 500, 3), dtype=np.uint8)\n",
    "\n",
    "            y_grid, x_grid = np.ogrid[:500, :500]\n",
    "\n",
    "            # Full blob for pn1 on channel 0\n",
    "            center1 = (int(circle[\"pn1\"][\"x\"]), int(circle[\"pn1\"][\"y\"]))\n",
    "            radius1 = int(circle[\"pn1\"][\"r\"])\n",
    "            blob1 = (x_grid - center1[0]) ** 2 + (\n",
    "                y_grid - center1[1]\n",
    "            ) ** 2 <= radius1**2\n",
    "            mask[..., 1][blob1] = 255\n",
    "\n",
    "            # Full blob for pn2 on channel 1, if available\n",
    "            if circle[\"pn2\"]:\n",
    "                center2 = (int(circle[\"pn2\"][\"x\"]), int(circle[\"pn2\"][\"y\"]))\n",
    "                radius2 = int(circle[\"pn2\"][\"r\"])\n",
    "                blob2 = (x_grid - center2[0]) ** 2 + (\n",
    "                    y_grid - center2[1]\n",
    "                ) ** 2 <= radius2**2\n",
    "                mask[..., 2][blob2] = 255\n",
    "\n",
    "            mask_image = Image.fromarray(mask)\n",
    "            images.append(frame_img)\n",
    "            masks.append(mask_image)\n",
    "\n",
    "    dataset = ImageDataset(images=images, masks=masks, transform=False)\n",
    "\n",
    "    dataloader = DataLoader(dataset=dataset, shuffle=False, batch_size=BATCH_SIZE)\n",
    "\n",
    "    whole_embryo_segmentation_model.eval()\n",
    "    whole_embryo_segmentation_model.to(DEVICE)\n",
    "\n",
    "    complete_masks = []\n",
    "    for batch_im, batch_mask in tqdm(dataloader):\n",
    "\n",
    "        batch_im = batch_im.to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            pred_masks = (\n",
    "            torch.sigmoid(\n",
    "                inference(\n",
    "                    whole_embryo_segmentation_model,\n",
    "                    batch_im,\n",
    "                    precision=InferencePrecision.FULL\n",
    "                )\n",
    "            )\n",
    "            > 0.8\n",
    "        )\n",
    "        \n",
    "        pred_masks = pred_masks.cpu().numpy()\n",
    "\n",
    "        for prd_msk, msk in zip(pred_masks, batch_mask.cpu().numpy()):\n",
    "            # breakpoint()\n",
    "\n",
    "            msk*=255\n",
    "\n",
    "            msk[0,...] = prd_msk.astype(int)*255\n",
    "\n",
    "            \n",
    "\n",
    "            complete_masks.append(Image.fromarray(msk.astype(np.uint8).transpose(1,2,0)))\n",
    "            # breakpoint()/\n",
    "            # break\n",
    "            # breakpoint()\n",
    "\n",
    "    \n",
    "    final_images = []\n",
    "    final_masks = []\n",
    "\n",
    "    for im, msk in zip(images, complete_masks):\n",
    "        \n",
    "        msk_ar = np.array(msk)[:,:,0]\n",
    "        \n",
    "        if msk_ar.sum()<190190:\n",
    "            continue\n",
    "\n",
    "        final_images.append(im)\n",
    "        final_masks.append(msk)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    return final_images, final_masks\n",
    "\n",
    "\n",
    "class InferencePrecision(StrEnum):\n",
    "    FULL = \"full\"\n",
    "    HALF = \"half\"\n",
    "    MIXED = \"mixed\"\n",
    "\n",
    "\n",
    "\n",
    "def inference(model, X, precision: InferencePrecision = InferencePrecision.FULL, *args):\n",
    "\n",
    "    match precision:\n",
    "        case InferencePrecision.MIXED:\n",
    "            with autocast():\n",
    "                return model(X, *args)\n",
    "\n",
    "        case InferencePrecision.FULL:\n",
    "            with torch.no_grad():\n",
    "                return model(X, *args)\n",
    "\n",
    "    return model(X, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 2316/9538 [00:11<00:36, 198.31it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/tsakalis/ntua/phd/cellforge/cellforge/data/raw_timelapses/D2011.07.09_S0085_I149_1/59_0.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m images, masks \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_all_masks_separate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[59], line 54\u001b[0m, in \u001b[0;36mcreate_all_masks_separate\u001b[0;34m(whole_embryo_segmentation_model)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m circle \u001b[38;5;129;01min\u001b[39;00m circles:\n\u001b[1;32m     53\u001b[0m     full_frame_pth \u001b[38;5;241m=\u001b[39m timelapse_pth \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mslide_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcircle[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_0.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 54\u001b[0m     frame_img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_frame_pth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m3\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m     57\u001b[0m     y_grid, x_grid \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mogrid[:\u001b[38;5;241m500\u001b[39m, :\u001b[38;5;241m500\u001b[39m]\n",
      "File \u001b[0;32m~/ntua/phd/cellforge/cellforge_venv/lib/python3.12/site-packages/PIL/Image.py:3469\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3466\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mfspath(fp))\n\u001b[1;32m   3468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3469\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3470\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/tsakalis/ntua/phd/cellforge/cellforge/data/raw_timelapses/D2011.07.09_S0085_I149_1/59_0.jpg'"
     ]
    }
   ],
   "source": [
    "images, masks = create_all_masks_separate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 12288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(12288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(12288, 12288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(12288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(12288, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 12288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(12288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(12288, 12288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(12288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(12288, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 12288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(12288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(12288, 12288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(12288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(12288, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(3072, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(768, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pronuclei.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 200/200 [00:00<00:00, 44304.47it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ImageCircleDataset.__init__() missing 3 required positional arguments: 'circles', 'whole_embryo_mask', and 'pn_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m all_pn_areas \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample_idx, sample_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sample_ids):\n\u001b[0;32m---> 11\u001b[0m     slide_images, slide_masks \u001b[38;5;241m=\u001b[39m \u001b[43minference_whole_slide\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_pronuclei\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_path\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43msample_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     all_pn_areas\u001b[38;5;241m.\u001b[39mappend(pn_area)\n\u001b[1;32m     14\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(pn_area)\n",
      "Cell \u001b[0;32mIn[56], line 15\u001b[0m, in \u001b[0;36minference_whole_slide\u001b[0;34m(model, slide_pth, max_frame)\u001b[0m\n\u001b[1;32m     10\u001b[0m image_file_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mlist\u001b[39m(slide_pth\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[1;32m     11\u001b[0m                         key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mint\u001b[39m(x\u001b[38;5;241m.\u001b[39mstem))[:max_frame]\n\u001b[1;32m     13\u001b[0m images \u001b[38;5;241m=\u001b[39m [Image\u001b[38;5;241m.\u001b[39mopen(img_path) \u001b[38;5;28;01mfor\u001b[39;00m img_path \u001b[38;5;129;01min\u001b[39;00m tqdm(image_file_paths)]\n\u001b[0;32m---> 15\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mImageCircleDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m val_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mTypeError\u001b[0m: ImageCircleDataset.__init__() missing 3 required positional arguments: 'circles', 'whole_embryo_mask', and 'pn_mask'"
     ]
    }
   ],
   "source": [
    "sample_ids = [\n",
    "            'D2016.07.08_S1366_I149_11',\n",
    "            'D2016.10.18_S1418_I149_6',\n",
    "            'D2016.10.18_S1418_I149_8',\n",
    "            'D2016.10.18_S1418_I149_11'\n",
    "            ]\n",
    "\n",
    "all_pn_areas = []\n",
    "for sample_idx, sample_id in enumerate(sample_ids):\n",
    "\n",
    "    slide_images, slide_masks = inference_whole_slide(model_pronuclei, sample_path/sample_id, 200)\n",
    "    all_pn_areas.append(pn_area)\n",
    "\n",
    "    plt.plot(pn_area)\n",
    "    output_path = Path(f\"/home/tsakalis/pn_samples/accumulated_pn_area_sample_whole{sample_idx}_multilabel.mp4\")\n",
    "    generate_video(slide_images, slide_masks, output_path)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 12288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(12288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(12288, 12288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(12288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(12288, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 12288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(12288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(12288, 12288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(12288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(12288, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 12288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(12288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(12288, 12288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(12288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(12288, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(3072, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(768, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = np.load(\"/media/tsakalis/STORAGE/phd/pronuclei_tracking/masks/D2016.07.08_S1366_I149_11.npz\")['all_masks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x74c528168ad0>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.sum(masks,axis=(1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Unet:\n\tMissing key(s) in state_dict: \"encoder.layer2.4.conv1.weight\", \"encoder.layer2.4.bn1.weight\", \"encoder.layer2.4.bn1.bias\", \"encoder.layer2.4.bn1.running_mean\", \"encoder.layer2.4.bn1.running_var\", \"encoder.layer2.4.conv2.weight\", \"encoder.layer2.4.bn2.weight\", \"encoder.layer2.4.bn2.bias\", \"encoder.layer2.4.bn2.running_mean\", \"encoder.layer2.4.bn2.running_var\", \"encoder.layer2.4.conv3.weight\", \"encoder.layer2.4.bn3.weight\", \"encoder.layer2.4.bn3.bias\", \"encoder.layer2.4.bn3.running_mean\", \"encoder.layer2.4.bn3.running_var\", \"encoder.layer2.5.conv1.weight\", \"encoder.layer2.5.bn1.weight\", \"encoder.layer2.5.bn1.bias\", \"encoder.layer2.5.bn1.running_mean\", \"encoder.layer2.5.bn1.running_var\", \"encoder.layer2.5.conv2.weight\", \"encoder.layer2.5.bn2.weight\", \"encoder.layer2.5.bn2.bias\", \"encoder.layer2.5.bn2.running_mean\", \"encoder.layer2.5.bn2.running_var\", \"encoder.layer2.5.conv3.weight\", \"encoder.layer2.5.bn3.weight\", \"encoder.layer2.5.bn3.bias\", \"encoder.layer2.5.bn3.running_mean\", \"encoder.layer2.5.bn3.running_var\", \"encoder.layer2.6.conv1.weight\", \"encoder.layer2.6.bn1.weight\", \"encoder.layer2.6.bn1.bias\", \"encoder.layer2.6.bn1.running_mean\", \"encoder.layer2.6.bn1.running_var\", \"encoder.layer2.6.conv2.weight\", \"encoder.layer2.6.bn2.weight\", \"encoder.layer2.6.bn2.bias\", \"encoder.layer2.6.bn2.running_mean\", \"encoder.layer2.6.bn2.running_var\", \"encoder.layer2.6.conv3.weight\", \"encoder.layer2.6.bn3.weight\", \"encoder.layer2.6.bn3.bias\", \"encoder.layer2.6.bn3.running_mean\", \"encoder.layer2.6.bn3.running_var\", \"encoder.layer2.7.conv1.weight\", \"encoder.layer2.7.bn1.weight\", \"encoder.layer2.7.bn1.bias\", \"encoder.layer2.7.bn1.running_mean\", \"encoder.layer2.7.bn1.running_var\", \"encoder.layer2.7.conv2.weight\", \"encoder.layer2.7.bn2.weight\", \"encoder.layer2.7.bn2.bias\", \"encoder.layer2.7.bn2.running_mean\", \"encoder.layer2.7.bn2.running_var\", \"encoder.layer2.7.conv3.weight\", \"encoder.layer2.7.bn3.weight\", \"encoder.layer2.7.bn3.bias\", \"encoder.layer2.7.bn3.running_mean\", \"encoder.layer2.7.bn3.running_var\", \"encoder.layer3.23.conv1.weight\", \"encoder.layer3.23.bn1.weight\", \"encoder.layer3.23.bn1.bias\", \"encoder.layer3.23.bn1.running_mean\", \"encoder.layer3.23.bn1.running_var\", \"encoder.layer3.23.conv2.weight\", \"encoder.layer3.23.bn2.weight\", \"encoder.layer3.23.bn2.bias\", \"encoder.layer3.23.bn2.running_mean\", \"encoder.layer3.23.bn2.running_var\", \"encoder.layer3.23.conv3.weight\", \"encoder.layer3.23.bn3.weight\", \"encoder.layer3.23.bn3.bias\", \"encoder.layer3.23.bn3.running_mean\", \"encoder.layer3.23.bn3.running_var\", \"encoder.layer3.24.conv1.weight\", \"encoder.layer3.24.bn1.weight\", \"encoder.layer3.24.bn1.bias\", \"encoder.layer3.24.bn1.running_mean\", \"encoder.layer3.24.bn1.running_var\", \"encoder.layer3.24.conv2.weight\", \"encoder.layer3.24.bn2.weight\", \"encoder.layer3.24.bn2.bias\", \"encoder.layer3.24.bn2.running_mean\", \"encoder.layer3.24.bn2.running_var\", \"encoder.layer3.24.conv3.weight\", \"encoder.layer3.24.bn3.weight\", \"encoder.layer3.24.bn3.bias\", \"encoder.layer3.24.bn3.running_mean\", \"encoder.layer3.24.bn3.running_var\", \"encoder.layer3.25.conv1.weight\", \"encoder.layer3.25.bn1.weight\", \"encoder.layer3.25.bn1.bias\", \"encoder.layer3.25.bn1.running_mean\", \"encoder.layer3.25.bn1.running_var\", \"encoder.layer3.25.conv2.weight\", \"encoder.layer3.25.bn2.weight\", \"encoder.layer3.25.bn2.bias\", \"encoder.layer3.25.bn2.running_mean\", \"encoder.layer3.25.bn2.running_var\", \"encoder.layer3.25.conv3.weight\", \"encoder.layer3.25.bn3.weight\", \"encoder.layer3.25.bn3.bias\", \"encoder.layer3.25.bn3.running_mean\", \"encoder.layer3.25.bn3.running_var\", \"encoder.layer3.26.conv1.weight\", \"encoder.layer3.26.bn1.weight\", \"encoder.layer3.26.bn1.bias\", \"encoder.layer3.26.bn1.running_mean\", \"encoder.layer3.26.bn1.running_var\", \"encoder.layer3.26.conv2.weight\", \"encoder.layer3.26.bn2.weight\", \"encoder.layer3.26.bn2.bias\", \"encoder.layer3.26.bn2.running_mean\", \"encoder.layer3.26.bn2.running_var\", \"encoder.layer3.26.conv3.weight\", \"encoder.layer3.26.bn3.weight\", \"encoder.layer3.26.bn3.bias\", \"encoder.layer3.26.bn3.running_mean\", \"encoder.layer3.26.bn3.running_var\", \"encoder.layer3.27.conv1.weight\", \"encoder.layer3.27.bn1.weight\", \"encoder.layer3.27.bn1.bias\", \"encoder.layer3.27.bn1.running_mean\", \"encoder.layer3.27.bn1.running_var\", \"encoder.layer3.27.conv2.weight\", \"encoder.layer3.27.bn2.weight\", \"encoder.layer3.27.bn2.bias\", \"encoder.layer3.27.bn2.running_mean\", \"encoder.layer3.27.bn2.running_var\", \"encoder.layer3.27.conv3.weight\", \"encoder.layer3.27.bn3.weight\", \"encoder.layer3.27.bn3.bias\", \"encoder.layer3.27.bn3.running_mean\", \"encoder.layer3.27.bn3.running_var\", \"encoder.layer3.28.conv1.weight\", \"encoder.layer3.28.bn1.weight\", \"encoder.layer3.28.bn1.bias\", \"encoder.layer3.28.bn1.running_mean\", \"encoder.layer3.28.bn1.running_var\", \"encoder.layer3.28.conv2.weight\", \"encoder.layer3.28.bn2.weight\", \"encoder.layer3.28.bn2.bias\", \"encoder.layer3.28.bn2.running_mean\", \"encoder.layer3.28.bn2.running_var\", \"encoder.layer3.28.conv3.weight\", \"encoder.layer3.28.bn3.weight\", \"encoder.layer3.28.bn3.bias\", \"encoder.layer3.28.bn3.running_mean\", \"encoder.layer3.28.bn3.running_var\", \"encoder.layer3.29.conv1.weight\", \"encoder.layer3.29.bn1.weight\", \"encoder.layer3.29.bn1.bias\", \"encoder.layer3.29.bn1.running_mean\", \"encoder.layer3.29.bn1.running_var\", \"encoder.layer3.29.conv2.weight\", \"encoder.layer3.29.bn2.weight\", \"encoder.layer3.29.bn2.bias\", \"encoder.layer3.29.bn2.running_mean\", \"encoder.layer3.29.bn2.running_var\", \"encoder.layer3.29.conv3.weight\", \"encoder.layer3.29.bn3.weight\", \"encoder.layer3.29.bn3.bias\", \"encoder.layer3.29.bn3.running_mean\", \"encoder.layer3.29.bn3.running_var\", \"encoder.layer3.30.conv1.weight\", \"encoder.layer3.30.bn1.weight\", \"encoder.layer3.30.bn1.bias\", \"encoder.layer3.30.bn1.running_mean\", \"encoder.layer3.30.bn1.running_var\", \"encoder.layer3.30.conv2.weight\", \"encoder.layer3.30.bn2.weight\", \"encoder.layer3.30.bn2.bias\", \"encoder.layer3.30.bn2.running_mean\", \"encoder.layer3.30.bn2.running_var\", \"encoder.layer3.30.conv3.weight\", \"encoder.layer3.30.bn3.weight\", \"encoder.layer3.30.bn3.bias\", \"encoder.layer3.30.bn3.running_mean\", \"encoder.layer3.30.bn3.running_var\", \"encoder.layer3.31.conv1.weight\", \"encoder.layer3.31.bn1.weight\", \"encoder.layer3.31.bn1.bias\", \"encoder.layer3.31.bn1.running_mean\", \"encoder.layer3.31.bn1.running_var\", \"encoder.layer3.31.conv2.weight\", \"encoder.layer3.31.bn2.weight\", \"encoder.layer3.31.bn2.bias\", \"encoder.layer3.31.bn2.running_mean\", \"encoder.layer3.31.bn2.running_var\", \"encoder.layer3.31.conv3.weight\", \"encoder.layer3.31.bn3.weight\", \"encoder.layer3.31.bn3.bias\", \"encoder.layer3.31.bn3.running_mean\", \"encoder.layer3.31.bn3.running_var\", \"encoder.layer3.32.conv1.weight\", \"encoder.layer3.32.bn1.weight\", \"encoder.layer3.32.bn1.bias\", \"encoder.layer3.32.bn1.running_mean\", \"encoder.layer3.32.bn1.running_var\", \"encoder.layer3.32.conv2.weight\", \"encoder.layer3.32.bn2.weight\", \"encoder.layer3.32.bn2.bias\", \"encoder.layer3.32.bn2.running_mean\", \"encoder.layer3.32.bn2.running_var\", \"encoder.layer3.32.conv3.weight\", \"encoder.layer3.32.bn3.weight\", \"encoder.layer3.32.bn3.bias\", \"encoder.layer3.32.bn3.running_mean\", \"encoder.layer3.32.bn3.running_var\", \"encoder.layer3.33.conv1.weight\", \"encoder.layer3.33.bn1.weight\", \"encoder.layer3.33.bn1.bias\", \"encoder.layer3.33.bn1.running_mean\", \"encoder.layer3.33.bn1.running_var\", \"encoder.layer3.33.conv2.weight\", \"encoder.layer3.33.bn2.weight\", \"encoder.layer3.33.bn2.bias\", \"encoder.layer3.33.bn2.running_mean\", \"encoder.layer3.33.bn2.running_var\", \"encoder.layer3.33.conv3.weight\", \"encoder.layer3.33.bn3.weight\", \"encoder.layer3.33.bn3.bias\", \"encoder.layer3.33.bn3.running_mean\", \"encoder.layer3.33.bn3.running_var\", \"encoder.layer3.34.conv1.weight\", \"encoder.layer3.34.bn1.weight\", \"encoder.layer3.34.bn1.bias\", \"encoder.layer3.34.bn1.running_mean\", \"encoder.layer3.34.bn1.running_var\", \"encoder.layer3.34.conv2.weight\", \"encoder.layer3.34.bn2.weight\", \"encoder.layer3.34.bn2.bias\", \"encoder.layer3.34.bn2.running_mean\", \"encoder.layer3.34.bn2.running_var\", \"encoder.layer3.34.conv3.weight\", \"encoder.layer3.34.bn3.weight\", \"encoder.layer3.34.bn3.bias\", \"encoder.layer3.34.bn3.running_mean\", \"encoder.layer3.34.bn3.running_var\", \"encoder.layer3.35.conv1.weight\", \"encoder.layer3.35.bn1.weight\", \"encoder.layer3.35.bn1.bias\", \"encoder.layer3.35.bn1.running_mean\", \"encoder.layer3.35.bn1.running_var\", \"encoder.layer3.35.conv2.weight\", \"encoder.layer3.35.bn2.weight\", \"encoder.layer3.35.bn2.bias\", \"encoder.layer3.35.bn2.running_mean\", \"encoder.layer3.35.bn2.running_var\", \"encoder.layer3.35.conv3.weight\", \"encoder.layer3.35.bn3.weight\", \"encoder.layer3.35.bn3.bias\", \"encoder.layer3.35.bn3.running_mean\", \"encoder.layer3.35.bn3.running_var\". \n\tsize mismatch for encoder.layer1.0.conv1.weight: copying a param with shape torch.Size([512, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n\tsize mismatch for encoder.layer1.0.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.0.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.0.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.0.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.0.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for encoder.layer1.0.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.0.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.0.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.0.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.0.conv3.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n\tsize mismatch for encoder.layer1.1.conv1.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n\tsize mismatch for encoder.layer1.1.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.1.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.1.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.1.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.1.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for encoder.layer1.1.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.1.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.1.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.1.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.1.conv3.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n\tsize mismatch for encoder.layer1.2.conv1.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n\tsize mismatch for encoder.layer1.2.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.2.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.2.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.2.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.2.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for encoder.layer1.2.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.2.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.2.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.2.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.2.conv3.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n\tsize mismatch for encoder.layer2.0.conv1.weight: copying a param with shape torch.Size([1024, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for encoder.layer2.0.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.0.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.0.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.0.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.0.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for encoder.layer2.0.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.0.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.0.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.0.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.0.conv3.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n\tsize mismatch for encoder.layer2.1.conv1.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n\tsize mismatch for encoder.layer2.1.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.1.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.1.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.1.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.1.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for encoder.layer2.1.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.1.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.1.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.1.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.1.conv3.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n\tsize mismatch for encoder.layer2.2.conv1.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n\tsize mismatch for encoder.layer2.2.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.2.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.2.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.2.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.2.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for encoder.layer2.2.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.2.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.2.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.2.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.2.conv3.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n\tsize mismatch for encoder.layer2.3.conv1.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n\tsize mismatch for encoder.layer2.3.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.3.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.3.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.3.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.3.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for encoder.layer2.3.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.3.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.3.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.3.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.3.conv3.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n\tsize mismatch for encoder.layer3.0.conv1.weight: copying a param with shape torch.Size([2048, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for encoder.layer3.0.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.0.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.0.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.0.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.0.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.0.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.0.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.0.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.0.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.0.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.1.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.1.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.1.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.1.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.1.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.1.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.1.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.1.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.1.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.1.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.1.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.2.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.2.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.2.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.2.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.2.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.2.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.2.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.2.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.2.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.2.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.2.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.3.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.3.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.3.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.3.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.3.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.3.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.3.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.3.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.3.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.3.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.3.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.4.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.4.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.4.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.4.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.4.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.4.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.4.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.4.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.4.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.4.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.4.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.5.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.5.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.5.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.5.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.5.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.5.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.5.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.5.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.5.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.5.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.5.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.6.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.6.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.6.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.6.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.6.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.6.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.6.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.6.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.6.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.6.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.6.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.7.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.7.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.7.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.7.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.7.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.7.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.7.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.7.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.7.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.7.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.7.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.8.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.8.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.8.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.8.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.8.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.8.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.8.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.8.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.8.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.8.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.8.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.9.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.9.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.9.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.9.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.9.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.9.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.9.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.9.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.9.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.9.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.9.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.10.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.10.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.10.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.10.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.10.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.10.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.10.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.10.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.10.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.10.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.10.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.11.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.11.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.11.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.11.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.11.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.11.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.11.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.11.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.11.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.11.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.11.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.12.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.12.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.12.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.12.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.12.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.12.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.12.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.12.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.12.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.12.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.12.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.13.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.13.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.13.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.13.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.13.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.13.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.13.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.13.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.13.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.13.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.13.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.14.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.14.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.14.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.14.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.14.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.14.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.14.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.14.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.14.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.14.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.14.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.15.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.15.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.15.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.15.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.15.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.15.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.15.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.15.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.15.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.15.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.15.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.16.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.16.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.16.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.16.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.16.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.16.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.16.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.16.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.16.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.16.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.16.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.17.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.17.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.17.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.17.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.17.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.17.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.17.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.17.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.17.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.17.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.17.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.18.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.18.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.18.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.18.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.18.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.18.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.18.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.18.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.18.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.18.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.18.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.19.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.19.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.19.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.19.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.19.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.19.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.19.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.19.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.19.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.19.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.19.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.20.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.20.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.20.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.20.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.20.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.20.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.20.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.20.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.20.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.20.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.20.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.21.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.21.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.21.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.21.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.21.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.21.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.21.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.21.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.21.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.21.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.21.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.22.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.22.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.22.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.22.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.22.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.22.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.22.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.22.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.22.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.22.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.22.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer4.0.conv1.weight: copying a param with shape torch.Size([4096, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for encoder.layer4.0.bn1.weight: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.0.bn1.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.0.bn1.running_mean: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.0.bn1.running_var: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.0.conv2.weight: copying a param with shape torch.Size([4096, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for encoder.layer4.0.bn2.weight: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.0.bn2.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.0.bn2.running_mean: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.0.bn2.running_var: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.0.conv3.weight: copying a param with shape torch.Size([2048, 4096, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n\tsize mismatch for encoder.layer4.1.conv1.weight: copying a param with shape torch.Size([4096, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n\tsize mismatch for encoder.layer4.1.bn1.weight: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.1.bn1.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.1.bn1.running_mean: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.1.bn1.running_var: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.1.conv2.weight: copying a param with shape torch.Size([4096, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for encoder.layer4.1.bn2.weight: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.1.bn2.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.1.bn2.running_mean: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.1.bn2.running_var: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.1.conv3.weight: copying a param with shape torch.Size([2048, 4096, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n\tsize mismatch for encoder.layer4.2.conv1.weight: copying a param with shape torch.Size([4096, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n\tsize mismatch for encoder.layer4.2.bn1.weight: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.2.bn1.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.2.bn1.running_mean: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.2.bn1.running_var: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.2.conv2.weight: copying a param with shape torch.Size([4096, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for encoder.layer4.2.bn2.weight: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.2.bn2.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.2.bn2.running_mean: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.2.bn2.running_var: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.2.conv3.weight: copying a param with shape torch.Size([2048, 4096, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 24\u001b[0m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m smp\u001b[38;5;241m.\u001b[39mUnet(\n\u001b[1;32m      8\u001b[0m     encoder_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresnet152\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     encoder_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     11\u001b[0m     classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#     classes=3,\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_weights\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minner_embryo.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/ntua/phd/cellforge/cellforge_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:2593\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2585\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2586\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2587\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2588\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2589\u001b[0m             ),\n\u001b[1;32m   2590\u001b[0m         )\n\u001b[1;32m   2592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2594\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2595\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2596\u001b[0m         )\n\u001b[1;32m   2597\u001b[0m     )\n\u001b[1;32m   2598\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Unet:\n\tMissing key(s) in state_dict: \"encoder.layer2.4.conv1.weight\", \"encoder.layer2.4.bn1.weight\", \"encoder.layer2.4.bn1.bias\", \"encoder.layer2.4.bn1.running_mean\", \"encoder.layer2.4.bn1.running_var\", \"encoder.layer2.4.conv2.weight\", \"encoder.layer2.4.bn2.weight\", \"encoder.layer2.4.bn2.bias\", \"encoder.layer2.4.bn2.running_mean\", \"encoder.layer2.4.bn2.running_var\", \"encoder.layer2.4.conv3.weight\", \"encoder.layer2.4.bn3.weight\", \"encoder.layer2.4.bn3.bias\", \"encoder.layer2.4.bn3.running_mean\", \"encoder.layer2.4.bn3.running_var\", \"encoder.layer2.5.conv1.weight\", \"encoder.layer2.5.bn1.weight\", \"encoder.layer2.5.bn1.bias\", \"encoder.layer2.5.bn1.running_mean\", \"encoder.layer2.5.bn1.running_var\", \"encoder.layer2.5.conv2.weight\", \"encoder.layer2.5.bn2.weight\", \"encoder.layer2.5.bn2.bias\", \"encoder.layer2.5.bn2.running_mean\", \"encoder.layer2.5.bn2.running_var\", \"encoder.layer2.5.conv3.weight\", \"encoder.layer2.5.bn3.weight\", \"encoder.layer2.5.bn3.bias\", \"encoder.layer2.5.bn3.running_mean\", \"encoder.layer2.5.bn3.running_var\", \"encoder.layer2.6.conv1.weight\", \"encoder.layer2.6.bn1.weight\", \"encoder.layer2.6.bn1.bias\", \"encoder.layer2.6.bn1.running_mean\", \"encoder.layer2.6.bn1.running_var\", \"encoder.layer2.6.conv2.weight\", \"encoder.layer2.6.bn2.weight\", \"encoder.layer2.6.bn2.bias\", \"encoder.layer2.6.bn2.running_mean\", \"encoder.layer2.6.bn2.running_var\", \"encoder.layer2.6.conv3.weight\", \"encoder.layer2.6.bn3.weight\", \"encoder.layer2.6.bn3.bias\", \"encoder.layer2.6.bn3.running_mean\", \"encoder.layer2.6.bn3.running_var\", \"encoder.layer2.7.conv1.weight\", \"encoder.layer2.7.bn1.weight\", \"encoder.layer2.7.bn1.bias\", \"encoder.layer2.7.bn1.running_mean\", \"encoder.layer2.7.bn1.running_var\", \"encoder.layer2.7.conv2.weight\", \"encoder.layer2.7.bn2.weight\", \"encoder.layer2.7.bn2.bias\", \"encoder.layer2.7.bn2.running_mean\", \"encoder.layer2.7.bn2.running_var\", \"encoder.layer2.7.conv3.weight\", \"encoder.layer2.7.bn3.weight\", \"encoder.layer2.7.bn3.bias\", \"encoder.layer2.7.bn3.running_mean\", \"encoder.layer2.7.bn3.running_var\", \"encoder.layer3.23.conv1.weight\", \"encoder.layer3.23.bn1.weight\", \"encoder.layer3.23.bn1.bias\", \"encoder.layer3.23.bn1.running_mean\", \"encoder.layer3.23.bn1.running_var\", \"encoder.layer3.23.conv2.weight\", \"encoder.layer3.23.bn2.weight\", \"encoder.layer3.23.bn2.bias\", \"encoder.layer3.23.bn2.running_mean\", \"encoder.layer3.23.bn2.running_var\", \"encoder.layer3.23.conv3.weight\", \"encoder.layer3.23.bn3.weight\", \"encoder.layer3.23.bn3.bias\", \"encoder.layer3.23.bn3.running_mean\", \"encoder.layer3.23.bn3.running_var\", \"encoder.layer3.24.conv1.weight\", \"encoder.layer3.24.bn1.weight\", \"encoder.layer3.24.bn1.bias\", \"encoder.layer3.24.bn1.running_mean\", \"encoder.layer3.24.bn1.running_var\", \"encoder.layer3.24.conv2.weight\", \"encoder.layer3.24.bn2.weight\", \"encoder.layer3.24.bn2.bias\", \"encoder.layer3.24.bn2.running_mean\", \"encoder.layer3.24.bn2.running_var\", \"encoder.layer3.24.conv3.weight\", \"encoder.layer3.24.bn3.weight\", \"encoder.layer3.24.bn3.bias\", \"encoder.layer3.24.bn3.running_mean\", \"encoder.layer3.24.bn3.running_var\", \"encoder.layer3.25.conv1.weight\", \"encoder.layer3.25.bn1.weight\", \"encoder.layer3.25.bn1.bias\", \"encoder.layer3.25.bn1.running_mean\", \"encoder.layer3.25.bn1.running_var\", \"encoder.layer3.25.conv2.weight\", \"encoder.layer3.25.bn2.weight\", \"encoder.layer3.25.bn2.bias\", \"encoder.layer3.25.bn2.running_mean\", \"encoder.layer3.25.bn2.running_var\", \"encoder.layer3.25.conv3.weight\", \"encoder.layer3.25.bn3.weight\", \"encoder.layer3.25.bn3.bias\", \"encoder.layer3.25.bn3.running_mean\", \"encoder.layer3.25.bn3.running_var\", \"encoder.layer3.26.conv1.weight\", \"encoder.layer3.26.bn1.weight\", \"encoder.layer3.26.bn1.bias\", \"encoder.layer3.26.bn1.running_mean\", \"encoder.layer3.26.bn1.running_var\", \"encoder.layer3.26.conv2.weight\", \"encoder.layer3.26.bn2.weight\", \"encoder.layer3.26.bn2.bias\", \"encoder.layer3.26.bn2.running_mean\", \"encoder.layer3.26.bn2.running_var\", \"encoder.layer3.26.conv3.weight\", \"encoder.layer3.26.bn3.weight\", \"encoder.layer3.26.bn3.bias\", \"encoder.layer3.26.bn3.running_mean\", \"encoder.layer3.26.bn3.running_var\", \"encoder.layer3.27.conv1.weight\", \"encoder.layer3.27.bn1.weight\", \"encoder.layer3.27.bn1.bias\", \"encoder.layer3.27.bn1.running_mean\", \"encoder.layer3.27.bn1.running_var\", \"encoder.layer3.27.conv2.weight\", \"encoder.layer3.27.bn2.weight\", \"encoder.layer3.27.bn2.bias\", \"encoder.layer3.27.bn2.running_mean\", \"encoder.layer3.27.bn2.running_var\", \"encoder.layer3.27.conv3.weight\", \"encoder.layer3.27.bn3.weight\", \"encoder.layer3.27.bn3.bias\", \"encoder.layer3.27.bn3.running_mean\", \"encoder.layer3.27.bn3.running_var\", \"encoder.layer3.28.conv1.weight\", \"encoder.layer3.28.bn1.weight\", \"encoder.layer3.28.bn1.bias\", \"encoder.layer3.28.bn1.running_mean\", \"encoder.layer3.28.bn1.running_var\", \"encoder.layer3.28.conv2.weight\", \"encoder.layer3.28.bn2.weight\", \"encoder.layer3.28.bn2.bias\", \"encoder.layer3.28.bn2.running_mean\", \"encoder.layer3.28.bn2.running_var\", \"encoder.layer3.28.conv3.weight\", \"encoder.layer3.28.bn3.weight\", \"encoder.layer3.28.bn3.bias\", \"encoder.layer3.28.bn3.running_mean\", \"encoder.layer3.28.bn3.running_var\", \"encoder.layer3.29.conv1.weight\", \"encoder.layer3.29.bn1.weight\", \"encoder.layer3.29.bn1.bias\", \"encoder.layer3.29.bn1.running_mean\", \"encoder.layer3.29.bn1.running_var\", \"encoder.layer3.29.conv2.weight\", \"encoder.layer3.29.bn2.weight\", \"encoder.layer3.29.bn2.bias\", \"encoder.layer3.29.bn2.running_mean\", \"encoder.layer3.29.bn2.running_var\", \"encoder.layer3.29.conv3.weight\", \"encoder.layer3.29.bn3.weight\", \"encoder.layer3.29.bn3.bias\", \"encoder.layer3.29.bn3.running_mean\", \"encoder.layer3.29.bn3.running_var\", \"encoder.layer3.30.conv1.weight\", \"encoder.layer3.30.bn1.weight\", \"encoder.layer3.30.bn1.bias\", \"encoder.layer3.30.bn1.running_mean\", \"encoder.layer3.30.bn1.running_var\", \"encoder.layer3.30.conv2.weight\", \"encoder.layer3.30.bn2.weight\", \"encoder.layer3.30.bn2.bias\", \"encoder.layer3.30.bn2.running_mean\", \"encoder.layer3.30.bn2.running_var\", \"encoder.layer3.30.conv3.weight\", \"encoder.layer3.30.bn3.weight\", \"encoder.layer3.30.bn3.bias\", \"encoder.layer3.30.bn3.running_mean\", \"encoder.layer3.30.bn3.running_var\", \"encoder.layer3.31.conv1.weight\", \"encoder.layer3.31.bn1.weight\", \"encoder.layer3.31.bn1.bias\", \"encoder.layer3.31.bn1.running_mean\", \"encoder.layer3.31.bn1.running_var\", \"encoder.layer3.31.conv2.weight\", \"encoder.layer3.31.bn2.weight\", \"encoder.layer3.31.bn2.bias\", \"encoder.layer3.31.bn2.running_mean\", \"encoder.layer3.31.bn2.running_var\", \"encoder.layer3.31.conv3.weight\", \"encoder.layer3.31.bn3.weight\", \"encoder.layer3.31.bn3.bias\", \"encoder.layer3.31.bn3.running_mean\", \"encoder.layer3.31.bn3.running_var\", \"encoder.layer3.32.conv1.weight\", \"encoder.layer3.32.bn1.weight\", \"encoder.layer3.32.bn1.bias\", \"encoder.layer3.32.bn1.running_mean\", \"encoder.layer3.32.bn1.running_var\", \"encoder.layer3.32.conv2.weight\", \"encoder.layer3.32.bn2.weight\", \"encoder.layer3.32.bn2.bias\", \"encoder.layer3.32.bn2.running_mean\", \"encoder.layer3.32.bn2.running_var\", \"encoder.layer3.32.conv3.weight\", \"encoder.layer3.32.bn3.weight\", \"encoder.layer3.32.bn3.bias\", \"encoder.layer3.32.bn3.running_mean\", \"encoder.layer3.32.bn3.running_var\", \"encoder.layer3.33.conv1.weight\", \"encoder.layer3.33.bn1.weight\", \"encoder.layer3.33.bn1.bias\", \"encoder.layer3.33.bn1.running_mean\", \"encoder.layer3.33.bn1.running_var\", \"encoder.layer3.33.conv2.weight\", \"encoder.layer3.33.bn2.weight\", \"encoder.layer3.33.bn2.bias\", \"encoder.layer3.33.bn2.running_mean\", \"encoder.layer3.33.bn2.running_var\", \"encoder.layer3.33.conv3.weight\", \"encoder.layer3.33.bn3.weight\", \"encoder.layer3.33.bn3.bias\", \"encoder.layer3.33.bn3.running_mean\", \"encoder.layer3.33.bn3.running_var\", \"encoder.layer3.34.conv1.weight\", \"encoder.layer3.34.bn1.weight\", \"encoder.layer3.34.bn1.bias\", \"encoder.layer3.34.bn1.running_mean\", \"encoder.layer3.34.bn1.running_var\", \"encoder.layer3.34.conv2.weight\", \"encoder.layer3.34.bn2.weight\", \"encoder.layer3.34.bn2.bias\", \"encoder.layer3.34.bn2.running_mean\", \"encoder.layer3.34.bn2.running_var\", \"encoder.layer3.34.conv3.weight\", \"encoder.layer3.34.bn3.weight\", \"encoder.layer3.34.bn3.bias\", \"encoder.layer3.34.bn3.running_mean\", \"encoder.layer3.34.bn3.running_var\", \"encoder.layer3.35.conv1.weight\", \"encoder.layer3.35.bn1.weight\", \"encoder.layer3.35.bn1.bias\", \"encoder.layer3.35.bn1.running_mean\", \"encoder.layer3.35.bn1.running_var\", \"encoder.layer3.35.conv2.weight\", \"encoder.layer3.35.bn2.weight\", \"encoder.layer3.35.bn2.bias\", \"encoder.layer3.35.bn2.running_mean\", \"encoder.layer3.35.bn2.running_var\", \"encoder.layer3.35.conv3.weight\", \"encoder.layer3.35.bn3.weight\", \"encoder.layer3.35.bn3.bias\", \"encoder.layer3.35.bn3.running_mean\", \"encoder.layer3.35.bn3.running_var\". \n\tsize mismatch for encoder.layer1.0.conv1.weight: copying a param with shape torch.Size([512, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n\tsize mismatch for encoder.layer1.0.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.0.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.0.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.0.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.0.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for encoder.layer1.0.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.0.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.0.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.0.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.0.conv3.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n\tsize mismatch for encoder.layer1.1.conv1.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n\tsize mismatch for encoder.layer1.1.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.1.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.1.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.1.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.1.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for encoder.layer1.1.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.1.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.1.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.1.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.1.conv3.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n\tsize mismatch for encoder.layer1.2.conv1.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n\tsize mismatch for encoder.layer1.2.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.2.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.2.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.2.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.2.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for encoder.layer1.2.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.2.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.2.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.2.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.layer1.2.conv3.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n\tsize mismatch for encoder.layer2.0.conv1.weight: copying a param with shape torch.Size([1024, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for encoder.layer2.0.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.0.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.0.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.0.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.0.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for encoder.layer2.0.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.0.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.0.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.0.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.0.conv3.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n\tsize mismatch for encoder.layer2.1.conv1.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n\tsize mismatch for encoder.layer2.1.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.1.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.1.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.1.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.1.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for encoder.layer2.1.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.1.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.1.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.1.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.1.conv3.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n\tsize mismatch for encoder.layer2.2.conv1.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n\tsize mismatch for encoder.layer2.2.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.2.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.2.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.2.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.2.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for encoder.layer2.2.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.2.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.2.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.2.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.2.conv3.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n\tsize mismatch for encoder.layer2.3.conv1.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n\tsize mismatch for encoder.layer2.3.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.3.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.3.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.3.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.3.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for encoder.layer2.3.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.3.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.3.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.3.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.layer2.3.conv3.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n\tsize mismatch for encoder.layer3.0.conv1.weight: copying a param with shape torch.Size([2048, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for encoder.layer3.0.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.0.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.0.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.0.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.0.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.0.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.0.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.0.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.0.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.0.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.1.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.1.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.1.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.1.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.1.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.1.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.1.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.1.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.1.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.1.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.1.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.2.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.2.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.2.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.2.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.2.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.2.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.2.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.2.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.2.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.2.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.2.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.3.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.3.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.3.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.3.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.3.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.3.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.3.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.3.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.3.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.3.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.3.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.4.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.4.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.4.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.4.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.4.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.4.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.4.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.4.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.4.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.4.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.4.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.5.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.5.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.5.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.5.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.5.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.5.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.5.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.5.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.5.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.5.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.5.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.6.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.6.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.6.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.6.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.6.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.6.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.6.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.6.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.6.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.6.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.6.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.7.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.7.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.7.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.7.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.7.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.7.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.7.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.7.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.7.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.7.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.7.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.8.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.8.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.8.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.8.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.8.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.8.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.8.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.8.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.8.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.8.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.8.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.9.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.9.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.9.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.9.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.9.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.9.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.9.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.9.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.9.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.9.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.9.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.10.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.10.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.10.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.10.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.10.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.10.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.10.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.10.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.10.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.10.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.10.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.11.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.11.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.11.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.11.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.11.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.11.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.11.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.11.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.11.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.11.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.11.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.12.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.12.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.12.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.12.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.12.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.12.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.12.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.12.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.12.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.12.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.12.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.13.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.13.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.13.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.13.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.13.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.13.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.13.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.13.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.13.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.13.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.13.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.14.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.14.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.14.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.14.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.14.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.14.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.14.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.14.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.14.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.14.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.14.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.15.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.15.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.15.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.15.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.15.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.15.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.15.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.15.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.15.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.15.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.15.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.16.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.16.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.16.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.16.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.16.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.16.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.16.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.16.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.16.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.16.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.16.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.17.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.17.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.17.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.17.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.17.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.17.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.17.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.17.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.17.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.17.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.17.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.18.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.18.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.18.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.18.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.18.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.18.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.18.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.18.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.18.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.18.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.18.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.19.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.19.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.19.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.19.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.19.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.19.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.19.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.19.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.19.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.19.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.19.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.20.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.20.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.20.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.20.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.20.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.20.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.20.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.20.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.20.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.20.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.20.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.21.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.21.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.21.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.21.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.21.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.21.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.21.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.21.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.21.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.21.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.21.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer3.22.conv1.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for encoder.layer3.22.bn1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.22.bn1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.22.bn1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.22.bn1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.22.conv2.weight: copying a param with shape torch.Size([2048, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder.layer3.22.bn2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.22.bn2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.22.bn2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.22.bn2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder.layer3.22.conv3.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n\tsize mismatch for encoder.layer4.0.conv1.weight: copying a param with shape torch.Size([4096, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for encoder.layer4.0.bn1.weight: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.0.bn1.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.0.bn1.running_mean: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.0.bn1.running_var: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.0.conv2.weight: copying a param with shape torch.Size([4096, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for encoder.layer4.0.bn2.weight: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.0.bn2.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.0.bn2.running_mean: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.0.bn2.running_var: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.0.conv3.weight: copying a param with shape torch.Size([2048, 4096, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n\tsize mismatch for encoder.layer4.1.conv1.weight: copying a param with shape torch.Size([4096, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n\tsize mismatch for encoder.layer4.1.bn1.weight: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.1.bn1.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.1.bn1.running_mean: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.1.bn1.running_var: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.1.conv2.weight: copying a param with shape torch.Size([4096, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for encoder.layer4.1.bn2.weight: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.1.bn2.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.1.bn2.running_mean: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.1.bn2.running_var: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.1.conv3.weight: copying a param with shape torch.Size([2048, 4096, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n\tsize mismatch for encoder.layer4.2.conv1.weight: copying a param with shape torch.Size([4096, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n\tsize mismatch for encoder.layer4.2.bn1.weight: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.2.bn1.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.2.bn1.running_mean: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.2.bn1.running_var: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.2.conv2.weight: copying a param with shape torch.Size([4096, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for encoder.layer4.2.bn2.weight: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.2.bn2.bias: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.2.bn2.running_mean: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.2.bn2.running_var: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.layer4.2.conv3.weight: copying a param with shape torch.Size([2048, 4096, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1])."
     ]
    }
   ],
   "source": [
    "model_weights = Path(\"/home/tsakalis/ntua/phd/cellforge/cellforge/model_weights\")\n",
    "\n",
    "# if __name__ == \"__main__\":/\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet152\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    ")\n",
    "\n",
    "# \n",
    "# \n",
    "# \n",
    "#  smp.Unet(\n",
    "#     encoder_name=\"resnext101_32x48d\",  # \"resnext101_32x48d\",\n",
    "#     encoder_weights=\"instagram\",\n",
    "#     in_channels=3,\n",
    "#     classes=3,\n",
    "# )\n",
    "\n",
    "model.load_state_dict(\n",
    "    torch.load(model_weights / \"inner_embryo.pt\", weights_only=True)\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom_in_pil(img: Image.Image, zoom_factor: float=1.5) -> Image.Image:\n",
    "    w, h = img.size\n",
    "    new_w = int(w / zoom_factor)\n",
    "    new_h = int(h / zoom_factor)\n",
    "    left = (w - new_w) // 2\n",
    "    top = (h - new_h) // 2\n",
    "    right = left + new_w\n",
    "    bottom = top + new_h\n",
    "\n",
    "    cropped = img.crop((left, top, right, bottom))\n",
    "    return cropped.resize((w, h), resample=Image.BICUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_all_masks_separate_circles():\n",
    "    \"\"\"\n",
    "    This function will take the pronuclei masks and create the other 2 classes.\n",
    "\n",
    "    We will need some extra samples to be used as counter examples\n",
    "    (when pronuclei are not showing).\n",
    "\n",
    "    \"\"\"\n",
    "    DEVICE = \"cuda\"\n",
    "    BATCH_SIZE = 32\n",
    "    MASK_THRESHOLD = 0.9\n",
    "    IMAGE_SIZE = 224\n",
    "\n",
    "    base_cicle_pth = Path(\"/media/tsakalis/STORAGE/phd/pronuclei_tracking\")\n",
    "    timelapse_pth = Path(\n",
    "        \"/home/tsakalis/ntua/phd/cellforge/cellforge/data/raw_timelapses\"\n",
    "    )\n",
    "    timelapse_pth_cold = Path(\"/media/tsakalis/STORAGE/phd/raw_timelapses\")\n",
    "\n",
    "    all_timelapses = list(timelapse_pth.glob(\"*\")) + list(timelapse_pth_cold.glob(\"*\"))\n",
    "\n",
    "    all_timelapses_map = {str(pth).split(\"/\")[-1]: pth for pth in all_timelapses}\n",
    "\n",
    "    all_circle_data = list((base_cicle_pth / \"fitted_circles_samples\").glob(\"*.json\"))\n",
    "    import json\n",
    "\n",
    "    images = []\n",
    "    full_circles = []\n",
    "    for circle_file_pth in tqdm(all_circle_data):\n",
    "        try:\n",
    "            slide_id = str(circle_file_pth).split(\"/\")[-1][:-5]\n",
    "\n",
    "            with open(circle_file_pth) as f:\n",
    "                circles = json.load(f)\n",
    "\n",
    "            for circle in circles:\n",
    "                try:\n",
    "                    full_frame_pth = (\n",
    "                        all_timelapses_map[slide_id] / f\"{circle['frame']}_0.jpg\"\n",
    "                    )\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                frame_img = Image.open(full_frame_pth).copy()\n",
    "\n",
    "                images.append((frame_img))\n",
    "                # frame_img.close()\n",
    "                full_circles.append(circle)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(e)\n",
    "\n",
    "    return images, full_circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms.functional import affine\n",
    "\n",
    "# # `img` can be a PIL image or a tensor\n",
    "# # zoom_factor > 1.0 means zoom in\n",
    "# zoom_factor = 1.2\n",
    "# image_size = img.size[-2:] if isinstance(img, torch.Tensor) else img.size[::-1]\n",
    "\n",
    "# img_zoomed = affine(\n",
    "#     img,\n",
    "#     angle=0,\n",
    "#     translate=[0, 0],\n",
    "#     scale=1 / zoom_factor,  # Inverse because scaling down zooms in\n",
    "#     shear=[0, 0],\n",
    "#     center=[s // 2 for s in image_size]\n",
    "# )\n",
    "\n",
    "\n",
    "class ImageCircleDataset(data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        images: list[ImageFile],\n",
    "        masks: list[ImageFile],\n",
    "        transform: bool = False,\n",
    "        image_size: int = 224,\n",
    "        problem_type: Literal[\"multiclass\", \"multilabel\"] = \"multilabel\",\n",
    "    ):\n",
    "        self.images = images\n",
    "        self.circles = masks\n",
    "        self.image_size = image_size\n",
    "        self.use_transform = transform\n",
    "        self.albumentations_transform = A.Compose(\n",
    "            [\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.5),\n",
    "                A.RandomRotate90(p=0.5),\n",
    "                A.Rotate(limit=90, p=0.5),\n",
    "                # A.ElasticTransform(p=0.2, alpha=1, sigma=50, alpha_affine=50),\n",
    "                A.Resize(self.image_size, self.image_size),\n",
    "            ],\n",
    "            additional_targets={\"mask\": \"mask\"},\n",
    "        )\n",
    "        self.type = problem_type\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def get_circle_stuff(self, circle: dict):\n",
    "        center_noise_std = 5  # pixels\n",
    "        radius_noise_std = 3  # pixels\n",
    "\n",
    "        if self.use_transform:\n",
    "            noise_center1 = np.random.normal(0, center_noise_std, size=2).astype(int)\n",
    "            noise_radius1 = int(np.random.normal(0, radius_noise_std))\n",
    "\n",
    "        else:\n",
    "\n",
    "            noise_center1 = [0, 0]\n",
    "            noise_radius1 = 0\n",
    "\n",
    "        center1 = (\n",
    "            int(circle[\"x\"]) + noise_center1[0],\n",
    "            int(circle[\"y\"]) + noise_center1[1],\n",
    "        )\n",
    "        radius1 = max(1, int(circle[\"r\"]) + noise_radius1)\n",
    "\n",
    "        return center1, radius1\n",
    "\n",
    "    def __getitem__(self, idx) -> tuple[torch.FloatTensor, torch.FloatTensor]:\n",
    "        import random\n",
    "        import numpy as np\n",
    "        from PIL import Image\n",
    "        import torchvision.transforms as T\n",
    "        import torchvision.transforms.functional as F\n",
    "        import torch\n",
    "\n",
    "        # Load image and circle data\n",
    "        image = self.images[idx]\n",
    "        img = self.images[idx].resize((self.image_size, self.image_size), Image.LANCZOS)\n",
    "        # circ_mask = self._make_circle_mask(self.circles[idx]).resize((self.image_size, self.image_size), Image.NEAREST)\n",
    "        # whole_mask = self.whole_embryo_masks[idx].resize((self.image_size, self.image_size), Image.NEAREST)\n",
    "        # pn_mask    = self.pn_masks[idx].resize((self.image_size, self.image_size), Image.NEAREST)\n",
    "\n",
    "        img = apply_clahe(img)\n",
    "        # 2) np arrays for albumentations\n",
    "        normalize_tensor = T.Compose(\n",
    "            [\n",
    "                T.Lambda(lambda x: x.convert(\"RGB\")),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "        img_np   = normalize_tensor(img).numpy()\n",
    "\n",
    "        return torch.from_numpy(img_np), torch.from_numpy(img_np)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from typing import Literal\n",
    "\n",
    "class ImageCircleDataset(data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        images: list[Image.Image],\n",
    "        # circles: list[dict],\n",
    "        # whole_embryo_masks: list[Image.Image],\n",
    "        # pn_masks: list[Image.Image],\n",
    "        # transform: bool = False,\n",
    "        image_size: int = 224,\n",
    "        # problem_type: Literal[\"multiclass\", \"multilabel\"] = \"multilabel\",\n",
    "    ):\n",
    "        # assert len(images)==len(circles)==len(whole_embryo_masks)==len(pn_masks)\n",
    "        self.images = images\n",
    "        self.image_size = image_size\n",
    "     #   self.circles = circles\n",
    "      #  self.whole_embryo_masks = whole_embryo_masks\n",
    "       # self.pn_masks = pn_masks\n",
    "            \n",
    "        self.use_transform = False\n",
    "      #  self.type = problem_type\n",
    "\n",
    "        # well stack: [pn1_circle, pn2_circle, whole_embryo_mask, pn_model_mask]\n",
    "        self.tf = A.Compose([\n",
    "                A.Rotate(limit=90, p=0.5),\n",
    "                A.ElasticTransform(p=0.2, alpha=1, sigma=50, alpha_affine=50),\n",
    "                A.Resize(self.image_size, self.image_size),\n",
    "                ],\n",
    "            additional_targets={\n",
    "                \"circle\": \"mask\",\n",
    "                \"whole_embryo\": \"mask\",\n",
    "                \"pn_model\": \"mask\",\n",
    "            },\n",
    "            is_check_shapes=False\n",
    "        )\n",
    "\n",
    "        # normalization to tensor\n",
    "        self.to_tensor = ToTensorV2()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def _make_circle_mask(self, circle: dict) -> Image.Image:\n",
    "\n",
    "    \n",
    "        # draw pn1/pn2 circles into a 3ch PIL.Image and return\n",
    "        H = W = 500  # original\n",
    "        mask = np.zeros((H, W, 3), dtype=np.uint8)\n",
    "        y, x = np.ogrid[:H, :W]\n",
    "\n",
    "        # pn1\n",
    "        c1 = (int(circle[\"pn1\"][\"x\"]), int(circle[\"pn1\"][\"y\"]))\n",
    "        r1 = int(circle[\"pn1\"][\"r\"])\n",
    "        blob1 = (x - c1[0])**2 + (y - c1[1])**2 <= r1**2\n",
    "        mask[...,1][blob1] = 255\n",
    "\n",
    "        # pn2 if exists\n",
    "        if circle.get(\"pn2\"):\n",
    "            c2 = (int(circle[\"pn2\"][\"x\"]), int(circle[\"pn2\"][\"y\"]))\n",
    "            r2 = int(circle[\"pn2\"][\"r\"])\n",
    "            blob2 = (x - c2[0])**2 + (y - c2[1])**2 <= r2**2\n",
    "            mask[...,2][blob2] = 255\n",
    "\n",
    "        return Image.fromarray(mask)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 1) load data\n",
    "        img = self.images[idx].resize((self.image_size, self.image_size), Image.LANCZOS)\n",
    "        # circ_mask = self._make_circle_mask(self.circles[idx]).resize((self.image_size, self.image_size), Image.NEAREST)\n",
    "        # whole_mask = self.whole_embryo_masks[idx].resize((self.image_size, self.image_size), Image.NEAREST)\n",
    "        # pn_mask    = self.pn_masks[idx].resize((self.image_size, self.image_size), Image.NEAREST)\n",
    "\n",
    "        img = apply_clahe(img)\n",
    "        # 2) np arrays for albumentations\n",
    "        normalize_tensor = T.Compose(\n",
    "            [\n",
    "                T.Lambda(lambda x: x.convert(\"RGB\")),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "        img_np   = normalize_tensor(img).numpy()\n",
    "        # circ_np  = np.array(circ_mask)\n",
    "        # whole_np = np.array(whole_mask)\n",
    "        # pn_np    = np.array(pn_mask)\n",
    "\n",
    "        # breakpoint()\n",
    "\n",
    "        # 3) optional augment\n",
    "        if self.use_transform:\n",
    "            aug = self.tf(\n",
    "                image=img_np.transpose(1,2,0),\n",
    "                circle=circ_np,\n",
    "                whole_embryo=whole_np,\n",
    "                pn_model=pn_np,\n",
    "            )\n",
    "            img_np   = aug[\"image\"]\n",
    "            circ_np  = aug[\"circle\"]\n",
    "            whole_np = aug[\"whole_embryo\"]\n",
    "            pn_np    = aug[\"pn_model\"]\n",
    "\n",
    "        else:\n",
    "            img_np = img_np.transpose(1,2,0)\n",
    "            \n",
    "\n",
    "        # breakpoint()\n",
    "        # 4) stack into a 4channel mask\n",
    "        #   circ_np.shape = (H, W, 3)  circle channels at indices 1 and 2\n",
    "        #   whole_np, pn_np are (H, W) or (H, W, 1)\n",
    "        # ensure singlechannel\n",
    "        # if whole_np.ndim==3: whole_np = whole_np[...,0]\n",
    "        # if pn_np.ndim==3:    pn_np    = pn_np[...,0]\n",
    "\n",
    "        # mask_stack = np.stack([\n",
    "        #     circ_np[...,1],        # pn1 circle\n",
    "        #     circ_np[...,2],        # pn2 circle\n",
    "        #     whole_np,              # wholeembryo prediction\n",
    "        #     pn_np,                 # pnmodel prediction\n",
    "        # ], axis=0)  # shape (4, H, W)\n",
    "\n",
    "        # 5) to tensor & normalize\n",
    "        out = {}\n",
    "        out[\"image\"] = self.to_tensor(image=img_np)[\"image\"]\n",
    "        # binary masks: 0 or 255  0.0 or 1.0\n",
    "        out[\"mask\"] =  self.to_tensor(image=img_np)[\"image\"]#torch.from_numpy(mask_stack.astype(np.float32) / 255.0)\n",
    "\n",
    "        return out[\"image\"].float(), out[\"mask\"]#[:-1,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(6144, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 12288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(12288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(12288, 12288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(12288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(12288, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 12288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(12288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(12288, 12288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(12288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(12288, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 12288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(12288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(12288, 12288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(12288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(12288, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(3072, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(768, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pronuclei = smp.Unet(\n",
    "        encoder_name=\"resnet18\",  # \"resnext101_32x48d\",\n",
    "        encoder_weights=\"imagenet\",\n",
    "        in_channels=3,\n",
    "        classes=2,\n",
    "\n",
    "    )\n",
    "\n",
    "model_pronuclei.load_state_dict(torch.load(\"/home/tsakalis/ntua/phd/cellforge/cellforge/model_weights/pronuclei_simple_extra.pt\", weights_only=True))\n",
    "model_pronuclei.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pronuclei.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnetPlusPlus(\n",
       "  (encoder): SENetEncoder(\n",
       "    (layer0): Sequential(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (2): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (2): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (3): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (2): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (3): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (4): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (5): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (6): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (7): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (8): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (9): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (10): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (11): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (12): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (13): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (14): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (15): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (16): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (17): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (18): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (19): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (20): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (21): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (22): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (2): SEResNeXtBottleneck(\n",
       "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (se_module): SEModule(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetPlusPlusDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleDict(\n",
       "      (x_0_0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(3072, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(1280, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_1_1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(896, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_1_2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_2_2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(320, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_1_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_2_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_3_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pronuclei.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 200/200 [00:00<00:00, 35335.33it/s]\n",
      "/tmp/ipykernel_2054540/1333030062.py:134: UserWarning: Argument(s) 'alpha_affine' are not valid for transform ElasticTransform\n",
      "  A.ElasticTransform(p=0.2, alpha=1, sigma=50, alpha_affine=50),\n",
      "/tmp/ipykernel_2054540/1284326114.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 200/200 [00:00<00:00, 34323.27it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 200/200 [00:00<00:00, 39239.44it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 200/200 [00:00<00:00, 39505.55it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "sample_ids = [\n",
    "            'D2016.07.08_S1366_I149_11',\n",
    "            'D2016.10.18_S1418_I149_6',\n",
    "            'D2016.10.18_S1418_I149_8',\n",
    "            'D2016.10.18_S1418_I149_11'\n",
    "            ]\n",
    "\n",
    "\n",
    "all_pn_areas = []\n",
    "for sample_idx, sample_id in enumerate(sample_ids):\n",
    "\n",
    "    slide_images, slide_masks = inference_whole_slide(model_pronuclei, sample_path/sample_id, 200)\n",
    "    # break\n",
    "    plt.plot(np.array([(a.sum(), b.sum()) for a, b in slide_masks]))\n",
    "    plt.show()\n",
    "\n",
    "    # plt.plot(pn_area)\n",
    "    output_path = Path(f\"/home/tsakalis/pn_samples/seperate_pn_{sample_idx}_multilabel_new.mp4\")\n",
    "    generate_video(slide_images, slide_masks, output_path)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slide_masks[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pn_area in all_pn_areas:\n",
    "    plt.plot(np.gradient(pn_area))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 560/560 [00:00<00:00, 40858.11it/s]\n"
     ]
    }
   ],
   "source": [
    "sample_path = Path(\n",
    "    \"/home/tsakalis/ntua/phd/cellforge/cellforge/data/D2016.10.18_S1418_I149_6\")\n",
    "\n",
    "image_file_paths = sorted(list(sample_path.glob('*.jpg')),\n",
    "                          key=lambda x: int(x.stem))\n",
    "\n",
    "images = [Image.open(img_path) for img_path in tqdm(image_file_paths)]\n",
    "\n",
    "# def remove_alpha(img):\n",
    "#     if img.mode == 'RGBA':  # If image has an alpha channel\n",
    "#         background = Image.new('RGB', img.size,\n",
    "#                                (255, 255, 255))  # Create white background\n",
    "#         background.paste(img, mask=img.split()[3])  # Use alpha channel as mask\n",
    "#         return background\n",
    "#     return img  # Return unchanged if no alpha channel\n",
    "\n",
    "# # Process images and masks\n",
    "# images = [remove_alpha(img) for img in tqdm(images)]\n",
    "# masks = [remove_alpha(msk) for msk in tqdm(masks)]\n",
    "\n",
    "# cropped_images = []\n",
    "# cropped_masks = []\n",
    "# for image, mask in zip(images, masks):\n",
    "\n",
    "#     cropped, cropped_mask = crop_around_center(image, mask, crop_size=200 * 3)\n",
    "\n",
    "#     cropped_images.append(cropped)\n",
    "#     cropped_masks.append(cropped_mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 150/150 [00:00<00:00, 34734.48it/s]\n",
      "/tmp/ipykernel_2072954/2015305102.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x79c1454b5580>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pn_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef_np(y_pred, y_true):\n",
    "\n",
    "    intersection = np.sum(y_true.flatten() * y_pred.flatten())\n",
    "    return (2. * intersection + smooth) / (\n",
    "        np.sum(y_true).flatten() + np.sum(y_pred).flatten() + smooth)\n",
    "\n",
    "\n",
    "def dice_loss(y_pred, y_true):\n",
    "\n",
    "    return 1.0 - dice_coef(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou_and_dice_np(pred, gt) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Compute IoU and Dice metrics for binary segmentation masks using PyTorch.\n",
    "\n",
    "    Args:\n",
    "        pred (torch.Tensor): Predicted binary mask (0 or 1), shape (H, W).\n",
    "        gt (torch.Tensor): Ground truth binary mask (0 or 1), shape (H, W).\n",
    "\n",
    "    Returns:\n",
    "        tuple[float, float]: IoU and Dice scores.\n",
    "    \"\"\"\n",
    "    # Ensure binary masks (threshold at 0.5 for soft predictions)\n",
    "    pred = (pred > 0.5).astype(float)\n",
    "    gt = (gt > 0.5).astype(float)\n",
    "\n",
    "    # Compute intersection and union\n",
    "    intersection = np.sum(pred * gt)\n",
    "    union = np.sum(pred) + np.sum(gt) - intersection\n",
    "\n",
    "    # Compute IoU\n",
    "    iou = (intersection / union).item() if union > 0 else 0.0\n",
    "\n",
    "    # Compute Dice coefficient\n",
    "    dice = (2 * intersection / (np.sum(pred) + np.sum(gt))).item() if (\n",
    "        np.sum(pred) + np.sum(gt)) > 0 else 0.0\n",
    "\n",
    "    return iou, dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 44 is out of bounds for axis 0 with size 40",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m minimize\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Load mask\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mmasks\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m44\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m      8\u001b[0m _, binary \u001b[38;5;241m=\u001b[39m _, mask\n\u001b[1;32m     10\u001b[0m H, W \u001b[38;5;241m=\u001b[39m binary\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mIndexError\u001b[0m: index 44 is out of bounds for axis 0 with size 40"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Load mask\n",
    "c = masks[44][0].astype(np.uint8)\n",
    "_, binary = _, mask\n",
    "\n",
    "H, W = binary.shape\n",
    "\n",
    "# Helper to draw a single circle mask\n",
    "def draw_circle(h, w, x, y, r):\n",
    "    Y, X = np.ogrid[:h, :w]\n",
    "    return ((X - x)**2 + (Y - y)**2) <= r**2\n",
    "\n",
    "# Loss function: overlap mismatch between union of circles and the binary mask\n",
    "def loss_fn(params):\n",
    "    x1, y1, r1, x2, y2, r2 = params\n",
    "    circle1 = draw_circle(H, W, x1, y1, r1)\n",
    "    circle2 = draw_circle(H, W, x2, y2, r2)\n",
    "    union = np.logical_or(circle1, circle2).astype(np.uint8)\n",
    "    iou, dice = compute_iou_and_dice_np(union,binary)\n",
    "    return -iou#dice_coef_np(union, binary)\n",
    "    \n",
    "\n",
    "# Initial guess: center of image and equal radii\n",
    "initial_guess = [W//3, H//2, 100, 2*W//3, H//2, 1]\n",
    "\n",
    "# Bounds to constrain solution\n",
    "bounds = [\n",
    "    (0, W), (0, H), (5, W//2),\n",
    "    (0, W), (0, H), (5, W//2),\n",
    "]\n",
    "\n",
    "# Run optimization\n",
    "result = minimize(loss_fn, initial_guess, bounds=bounds, method='L-BFGS-B')\n",
    "x1, y1, r1, x2, y2, r2 = result.x\n",
    "\n",
    "circle1 = draw_circle(H, W, x1, y1, r1)\n",
    "circle2 = draw_circle(H, W, x2, y2, r2)\n",
    "union = np.logical_or(circle1, circle2).astype(np.uint8)\n",
    "# Visualize\n",
    "result_mask = np.zeros((H, W), dtype=np.uint8)\n",
    "cv2.circle(result_mask, (int(x1), int(y1)), int(r1), 1, -1)\n",
    "cv2.circle(result_mask, (int(x2), int(y2)), int(r2), 1, -1)\n",
    "result_mask *= 255\n",
    "\n",
    "overlay = cv2.merge([binary * 255, result_mask, np.zeros_like(result_mask)])\n",
    "\n",
    "plt.imshow(overlay)\n",
    "plt.title(\"Green: Fitted Circles | Red: Original Mask\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2gray\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb2gray(isolated_pns[44])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.draw import ellipse\n",
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "from skimage.transform import rotate\n",
    "\n",
    "\n",
    "image = upscaled_masks[44]\n",
    "\n",
    "label_img = label(image)\n",
    "regions = regionprops(label_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(image, cmap=plt.cm.gray)\n",
    "\n",
    "for props in regions:\n",
    "    y0, x0 = props.centroid\n",
    "    orientation = props.orientation\n",
    "    x1 = x0 + math.cos(orientation) * 0.5 * props.axis_minor_length\n",
    "    y1 = y0 - math.sin(orientation) * 0.5 * props.axis_minor_length\n",
    "    x2 = x0 - math.sin(orientation) * 0.5 * props.axis_major_length\n",
    "    y2 = y0 - math.cos(orientation) * 0.5 * props.axis_major_length\n",
    "\n",
    "    ax.plot((x0, x1), (y0, y1), '-r', linewidth=1.5)\n",
    "    ax.plot((x0, x2), (y0, y2), '-r', linewidth=1.5)\n",
    "    ax.plot(x0, y0, '.g', markersize=15)\n",
    "\n",
    "    minr, minc, maxr, maxc = props.bbox\n",
    "    bx = (minc, maxc, maxc, minc, minc)\n",
    "    by = (minr, minr, maxr, maxr, minr)\n",
    "    # ax.plot(bx, by, '-b', linewidth=2.5)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[205], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m props \u001b[38;5;241m=\u001b[39m \u001b[43mregionprops_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_img\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproperties\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ntua/phd/cellforge/cellforge_venv/lib/python3.12/site-packages/skimage/measure/_regionprops.py:1106\u001b[0m, in \u001b[0;36mregionprops_table\u001b[0;34m(label_image, intensity_image, properties, cache, separator, extra_properties, spacing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m     out_d \u001b[38;5;241m=\u001b[39m _props_to_dict(regions, properties\u001b[38;5;241m=\u001b[39mproperties, separator\u001b[38;5;241m=\u001b[39mseparator)\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: v[:\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m out_d\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m-> 1106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_props_to_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperties\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproperties\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseparator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseparator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ntua/phd/cellforge/cellforge_venv/lib/python3.12/site-packages/skimage/measure/_regionprops.py:884\u001b[0m, in \u001b[0;36m_props_to_dict\u001b[0;34m(regions, properties, separator)\u001b[0m\n\u001b[1;32m    882\u001b[0m out \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    883\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(regions)\n\u001b[0;32m--> 884\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprop\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproperties\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mregions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Copy the original property name so the output will have the\u001b[39;49;00m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# user-provided property name in the case of deprecated names.\u001b[39;49;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "props = regionprops_table(\n",
    "    label_img,\n",
    "    properties=None\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'centroid-0': array([263.81139122]),\n",
       " 'centroid-1': array([249.22875817]),\n",
       " 'orientation': array([-1.21167299]),\n",
       " 'axis_major_length': array([50.30582695]),\n",
       " 'axis_minor_length': array([27.92539493])}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "props\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pred_mask = mask[0]\n",
    "sample_gt_image = image_ar[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (224,) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m axes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Prediction mask thresholded\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgray\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m axes[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Mask > 0.4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m axes[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/ntua/phd/cellforge/cellforge_venv/lib/python3.12/site-packages/matplotlib/__init__.py:1521\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1519\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1521\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1526\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1527\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1528\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/ntua/phd/cellforge/cellforge_venv/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5945\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, colorizer, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5942\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aspect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5943\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[0;32m-> 5945\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5946\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5948\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to Axes patch\u001b[39;00m\n",
      "File \u001b[0;32m~/ntua/phd/cellforge/cellforge_venv/lib/python3.12/site-packages/matplotlib/image.py:675\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[1;32m    674\u001b[0m     A \u001b[38;5;241m=\u001b[39m pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_normalize_image_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_imcache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/ntua/phd/cellforge/cellforge_venv/lib/python3.12/site-packages/matplotlib/image.py:643\u001b[0m, in \u001b[0;36m_ImageBase._normalize_image_array\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    641\u001b[0m     A \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# If just (M, N, 1), assume scalar and apply colormap.\u001b[39;00m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for image data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;66;03m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;66;03m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[1;32m    649\u001b[0m     high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(A\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (224,) for image data"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'source_image', 'sample_gt_mask', and 'sample_pred_mask' are numpy arrays\n",
    "# Display side by side\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Original ground truth mask\n",
    "axes[0].imshow(sample_gt_mask.numpy(), cmap='gray')\n",
    "axes[0].set_title(\"Ground Truth Mask\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Prediction mask thresholded\n",
    "axes[1].imshow(mask[0] > 0.4, cmap='gray')\n",
    "axes[1].set_title(\"Predicted Mask > 0.4\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Overlay source image with ground truth and predicted masks\n",
    "overlay_image = all_images[0][3][0].numpy().copy()\n",
    "# Adjust overlay to include masks for better visibility\n",
    "\n",
    "axes[2].imshow(overlay_image, cmap='gray')\n",
    "axes[2].set_title(\"Overlay with Source Image\")\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellforge_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
